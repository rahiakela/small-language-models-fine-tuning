{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/small-language-models-fine-tuning/blob/main/domain-specific-small-language-models/08-model-profiling/01_profiling_linear_regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn1T9F5L4Hhy"
      },
      "source": [
        "## Profiling Linear Regression ONNX Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code in this notebook is about profiling and getting performance insights for Linear Regression model after conversion to the [ONNX](https://onnx.ai/) format and optimization. The same code applies to any other LLM and the insights building part is generic for any ML/DL ONNX model profiling analysis. No hardware acceleration needed.  "
      ],
      "metadata": {
        "id": "grz4Smyy00Vq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePpgYStXAhul"
      },
      "source": [
        "Install the missing dependencies in the Colab VM (only ONNX and the ONNX runtime, plus mlprodict (for profiling data aggregation and clean up only). Please see note later in this notebook about the mlprodict package installation in later versions of the Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzUHU9px7RlC"
      },
      "outputs": [],
      "source": [
        "!pip install onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skl2onnx"
      ],
      "metadata": {
        "id": "xa77Mve24iS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlprodict"
      ],
      "metadata": {
        "id": "yomifw3E7kiB",
        "outputId": "90271dc2-81e8-4952-f7a4-da19c7ec9202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlprodict\n",
            "  Using cached mlprodict-0.9.1883.tar.gz (814 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNjxTAtDApie"
      },
      "source": [
        "Import the required packages and classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OIASY74Orrbr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b350a3b6-e8fa-4f62-ba68-9b64867ebd8e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mlprodict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1992459440.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlprodict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnxrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops_whole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxWholeSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlprodict'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from skl2onnx import to_onnx\n",
        "from mlprodict.onnxrt.ops_whole.session import OnnxWholeSession\n",
        "from onnxruntime import InferenceSession, SessionOptions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download diabetes dataset and then split the data into training and test."
      ],
      "metadata": {
        "id": "RjT98nTL3JX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_diabetes()"
      ],
      "metadata": {
        "id": "7_mhJke43NvN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, _ = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "fJRsnaa43ZGm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training Shape: {X_train.shape}, Testing Shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QubB0SD32Wx",
        "outputId": "af256e85-b84c-4bcf-fd03-ce8d7e9f2660"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Shape: (331, 10), Testing Shape: (111, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNM84XKAAswb"
      },
      "source": [
        "We can now train the model staying in the scikit-learn API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "73EvwK9Y2m6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "50eb0639-d26a-49d1-9c0a-d6b5edd89b52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "clr = LinearRegression()\n",
        "clr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRbxmJh2Bt5L"
      },
      "source": [
        "Export the model to ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hEzctUUd3jTc"
      },
      "outputs": [],
      "source": [
        "model_def = to_onnx(clr, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_def"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z40lEy2F46GS",
        "outputId": "c412e000-7b05-43ab-f760-1a7e791bf415"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelProto(ir_version=10, opset_import={'': 13}, domain='ai.onnx', producer_name='skl2onnx', producer_version='1.19.1', graph=GraphProto('ONNX(LinearRegression)', input=<1 inputs>, output=<1 outputs>, initializer=<3 initializers>, node=<3 nodes>))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEWJNnIwB9Yo"
      },
      "source": [
        "This converted model can be profiled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V19WofplAc05"
      },
      "outputs": [],
      "source": [
        "so = SessionOptions()\n",
        "so.enable_profiling = True\n",
        "\n",
        "sess = InferenceSession(model_def.SerializeToString(), so)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5djD_xrCJjm"
      },
      "source": [
        "We now run inference on the whole test set (111 samples) and stop the\n",
        "profiling at the end:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KPN1w6CDBEnJ"
      },
      "outputs": [],
      "source": [
        "sess.run(None, {\"X\": X_test})\n",
        "\n",
        "prof = sess.end_profiling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxu307dJCUed"
      },
      "source": [
        "We load now the generated raw profiling data from the created JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hjFo-ymc_8i9"
      },
      "outputs": [],
      "source": [
        "with open(prof, \"r\") as f:\n",
        "    js = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Saxm2LdFH4V"
      },
      "source": [
        "and then create a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RukFJF7_HLTq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYVqPvFv3M_"
      },
      "source": [
        "# Model Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEDfqWnQRgxn"
      },
      "source": [
        "Set up the logging level to see in the output which kind of optimizations are automatically applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BsBfm2k4Qxk"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig()\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nltxuz9PFWxY"
      },
      "source": [
        "Optimize the model using the ONNX's native optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcBMyBt-v6TD"
      },
      "outputs": [],
      "source": [
        "from onnxruntime.transformers import optimizer\n",
        "\n",
        "onnx_optim_model_path=\"gpt2onnx-opt.onnx\"\n",
        "optimized_model = optimizer.optimize_model(onnx_model_path,\n",
        "                                           model_type='gpt2',\n",
        "                                           num_heads=num_attention_heads,\n",
        "                                           hidden_size=hidden_size,\n",
        "                                           use_gpu=False,\n",
        "                                           opt_level=1,\n",
        "                                           verbose=True)\n",
        "optimized_model.convert_float_to_float16()\n",
        "optimized_model.save_model_to_file(onnx_optim_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbyTg-toFhcR"
      },
      "source": [
        "Run text generation using the ONNX optimized model with profiling enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgTqn1IJN9Ds"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "\n",
        "optimized_onnx_model = onnx.load(onnx_optim_model_path)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "input_ids, attention_mask, position_ids, empty_past = get_example_inputs(\n",
        "    ['Here is some text to encode Hello World'], tokenizer, num_layer)\n",
        "\n",
        "so = onnxruntime.SessionOptions()\n",
        "so.enable_profiling = True\n",
        "session = onnxruntime.InferenceSession(onnx_optim_model_path, so,\n",
        "                                       providers=[\"CPUExecutionProvider\"])\n",
        "ort_inputs = {\n",
        "    \"input_ids\": np.ascontiguousarray(input_ids.cpu().numpy()),\n",
        "}\n",
        "ort_outputs = session.run(None, ort_inputs)\n",
        "prof_optimized = session.end_profiling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnet0VAXFqFF"
      },
      "source": [
        "# Profiling Data Clean Up and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNq6hwS1OGSw"
      },
      "source": [
        "Copying and pasting here the original *mlprodict*'s `OnnxWholeSession` class code as the installation of this package is failing on the latest version of the Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGvuiu1GPCgW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy\n",
        "\n",
        "class OnnxWholeSession:\n",
        "    \"\"\"\n",
        "    Runs the prediction for a single :epkg:`ONNX`,\n",
        "    it lets the runtime handle the graph logic as well.\n",
        "\n",
        "    :param onnx_data: :epkg:`ONNX` model or data\n",
        "    :param runtime: runtime to be used, mostly :epkg:`onnxruntime`\n",
        "    :param runtime_options: runtime options\n",
        "    :param device: device, a string `cpu`, `cuda`, `cuda:0`...\n",
        "\n",
        "    .. versionchanged:: 0.8\n",
        "        Parameter *device* was added.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, onnx_data, runtime, runtime_options=None, device=None):\n",
        "        if runtime not in ('onnxruntime1', 'onnxruntime1-cuda'):\n",
        "            raise NotImplementedError(  # pragma: no cover\n",
        "                f\"runtime '{runtime}' is not implemented.\")\n",
        "\n",
        "        from onnxruntime import (  # delayed\n",
        "            InferenceSession, SessionOptions, RunOptions,\n",
        "            GraphOptimizationLevel)\n",
        "        from onnxruntime.capi._pybind_state import (  # pylint: disable=E0611\n",
        "            Fail as OrtFail, InvalidGraph as OrtInvalidGraph,\n",
        "            InvalidArgument as OrtInvalidArgument,\n",
        "            NotImplemented as OrtNotImplemented,\n",
        "            RuntimeException as OrtRuntimeException)\n",
        "\n",
        "        onnx_data0 = onnx_data\n",
        "        if hasattr(onnx_data, 'SerializeToString'):\n",
        "            onnx_data = onnx_data.SerializeToString()\n",
        "        if isinstance(runtime_options, SessionOptions):\n",
        "            sess_options = runtime_options\n",
        "            session_options = None\n",
        "            runtime_options = None\n",
        "        else:\n",
        "            session_options = (\n",
        "                None if runtime_options is None\n",
        "                else runtime_options.get('session_options', None))\n",
        "            self.runtime = runtime\n",
        "            sess_options = session_options or SessionOptions()\n",
        "        self.run_options = RunOptions()\n",
        "        self.run_options.log_severity_level = 3\n",
        "        self.run_options.log_verbosity_level = 1\n",
        "\n",
        "        if session_options is None:\n",
        "            if runtime_options is not None:\n",
        "                if runtime_options.get('disable_optimisation', False):\n",
        "                    sess_options.graph_optimization_level = (  # pragma: no cover\n",
        "                        GraphOptimizationLevel.ORT_ENABLE_ALL)\n",
        "                if runtime_options.get('enable_profiling', True):\n",
        "                    sess_options.enable_profiling = True\n",
        "                if runtime_options.get('log_severity_level', 2) != 2:\n",
        "                    v = runtime_options.get('log_severity_level', 2)\n",
        "                    sess_options.log_severity_level = v\n",
        "                    self.run_options.log_severity_level = v\n",
        "        elif runtime_options is not None and 'enable_profiling' in runtime_options:\n",
        "            raise RuntimeError(  # pragma: no cover\n",
        "                \"session_options and enable_profiling cannot be defined at the \"\n",
        "                \"same time.\")\n",
        "        elif runtime_options is not None and 'disable_optimisation' in runtime_options:\n",
        "            raise RuntimeError(  # pragma: no cover\n",
        "                \"session_options and disable_optimisation cannot be defined at the \"\n",
        "                \"same time.\")\n",
        "        elif runtime_options is not None and 'log_severity_level' in runtime_options:\n",
        "            raise RuntimeError(  # pragma: no cover\n",
        "                \"session_options and log_severity_level cannot be defined at the \"\n",
        "                \"same time.\")\n",
        "        providers = ['CPUExecutionProvider']\n",
        "        if runtime == 'onnxruntime1-cuda':\n",
        "            providers = ['CUDAExecutionProvider'] + providers\n",
        "        try:\n",
        "            self.sess = InferenceSession(onnx_data, sess_options=sess_options,\n",
        "                                         device=device, providers=providers)\n",
        "        except (OrtFail, OrtNotImplemented, OrtInvalidGraph,\n",
        "                OrtInvalidArgument, OrtRuntimeException, RuntimeError) as e:\n",
        "            raise RuntimeError(\n",
        "                \"Unable to create InferenceSession due to '{}'\\n{}.\".format(e)) from e\n",
        "        self.output_names = [_.name for _ in self.sess.get_outputs()]\n",
        "\n",
        "    def run(self, inputs):\n",
        "        \"\"\"\n",
        "        Computes the predictions.\n",
        "\n",
        "        @param      inputs      dictionary *{variable, value}*\n",
        "        @return                 list of outputs\n",
        "        \"\"\"\n",
        "        v = next(iter(inputs.values()))\n",
        "        if isinstance(v, (numpy.ndarray, dict)):\n",
        "            try:\n",
        "                return self.sess._sess.run(\n",
        "                    self.output_names, inputs, self.run_options)\n",
        "            except ValueError as e:\n",
        "                raise ValueError(\n",
        "                    \"Issue running inference inputs=%r, expected inputs=%r.\"\n",
        "                    \"\" % (\n",
        "                        list(sorted(inputs)),\n",
        "                        [i.name for i in self.sess.get_inputs()])) from e\n",
        "        try:\n",
        "            return self.sess._sess.run_with_ort_values(\n",
        "                inputs, self.output_names, self.run_options)\n",
        "        except RuntimeError:\n",
        "            return self.sess._sess.run_with_ort_values(\n",
        "                {k: v._get_c_value() for k, v in inputs.items()},\n",
        "                self.output_names, self.run_options)\n",
        "\n",
        "    @staticmethod\n",
        "    def process_profiling(js):\n",
        "        \"\"\"\n",
        "        Flattens json returned by onnxruntime profiling.\n",
        "\n",
        "        :param js: json\n",
        "        :return: list of dictionaries\n",
        "        \"\"\"\n",
        "        rows = []\n",
        "        for row in js:\n",
        "            if 'args' in row and isinstance(row['args'], dict):\n",
        "                for k, v in row['args'].items():\n",
        "                    row[f'args_{k}'] = v\n",
        "                del row['args']\n",
        "            rows.append(row)\n",
        "        return rows\n",
        "\n",
        "    def get_profiling(self):\n",
        "        \"\"\"\n",
        "        Returns the profiling informations.\n",
        "        \"\"\"\n",
        "        prof = self.sess.end_profiling()\n",
        "        with open(prof, 'r') as f:\n",
        "            content = f.read()\n",
        "        js = json.loads(content)\n",
        "        return OnnxWholeSession.process_profiling(js)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94AhN1kvGGLE"
      },
      "source": [
        "Define a custom function to put the raw ONNX profiling data in a more friendly and useful format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZgmisDGw1Ip"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def clean_up_profiling_data(prof):\n",
        "  with open(prof, \"r\") as f:\n",
        "      js = json.load(f)\n",
        "  df = pd.DataFrame(OnnxWholeSession.process_profiling(js))\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fBgZH6kG5oA"
      },
      "source": [
        "Define a custom function to do several profiling data aggregations (group by operator type and calculate the total duration for each one, count the number of occurrences for each one (and order them by duration), calculate the percentage of the total inference time for each one) that would be used to build some visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzVMU_34JFsN"
      },
      "outputs": [],
      "source": [
        "def transform_profiling_data_for_visualization(df):\n",
        "  gr_dur = df[['dur', \"args_op_name\"]].groupby(\"args_op_name\").sum().sort_values('dur')\n",
        "\n",
        "  gr_n = df[['dur', \"args_op_name\"]].groupby(\"args_op_name\").count().sort_values('dur')\n",
        "  gr_n = gr_n.loc[gr_dur.index, :]\n",
        "\n",
        "  gr_dur_perc = gr_dur / gr_dur['dur'].sum()\n",
        "\n",
        "  return gr_dur, gr_n, gr_dur_perc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek7GzdqZJz-l"
      },
      "source": [
        "Transform the profiling data for the ONNX model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmXh-UjzKDMX"
      },
      "outputs": [],
      "source": [
        "gr_dur, gr_n, gr_dur_perc = transform_profiling_data_for_visualization(clean_up_profiling_data(prof))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vupd5KSdKO6W"
      },
      "source": [
        "Create visualizations for the ONNX model profiling data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uec6ve0JKVOZ"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(gr_dur, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Duration (ms)\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Duration')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osIk4V4GKfBx"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(gr_n, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Op count\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Occurrences')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2LpQbd5Kinz"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(gr_dur_perc, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Duration (%)\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Proportion')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGDjmfkTKths"
      },
      "source": [
        "Transform the profiling data for the optimized ONNX model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BgEdxklKxJ2"
      },
      "outputs": [],
      "source": [
        "gr_dur, gr_n, gr_dur_perc = transform_profiling_data_for_visualization(clean_up_profiling_data(prof_optimized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhKzBjVGPpqV"
      },
      "source": [
        "Create visualizations for the optimized ONNX model profiling data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcU81S43Pw1x"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(gr_dur, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Duration (ms)\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Duration')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGE1-FxRP0H-"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(gr_n, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Op count\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Occurrences')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFxzpi9QP4A-"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(gr_dur_perc, x='dur',\n",
        "             labels={\n",
        "                     \"dur\": \"Duration (%)\",\n",
        "                     \"args_op_name\": \"Operation type\",\n",
        "                 },\n",
        "             title='Proportion')\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}