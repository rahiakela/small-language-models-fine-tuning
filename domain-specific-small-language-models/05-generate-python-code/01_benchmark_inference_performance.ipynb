{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9abf88f516b847dda3279889f1a5adf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4ba7126e2d541959dd99ac6583c6dac",
              "IPY_MODEL_e3f1c1789ede47f4ac202c584520ca85",
              "IPY_MODEL_c0632f863c514e5aa656973baa5da47f"
            ],
            "layout": "IPY_MODEL_d784d619716e476dabb98077307cc40b"
          }
        },
        "a4ba7126e2d541959dd99ac6583c6dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e505ec886442c68bbacd3af51388dc",
            "placeholder": "​",
            "style": "IPY_MODEL_74d036de785042789a161cebf872728b",
            "value": "config.json: 100%"
          }
        },
        "e3f1c1789ede47f4ac202c584520ca85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544995ebd611455b87512c58f627bc15",
            "max": 999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b7c95500ea04e54ab8ea4eaaae786e8",
            "value": 999
          }
        },
        "c0632f863c514e5aa656973baa5da47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23620e53560f41ac95f62ec499eadd73",
            "placeholder": "​",
            "style": "IPY_MODEL_ead9a2635f5c49aba7e8181a7dded53e",
            "value": " 999/999 [00:00&lt;00:00, 91.7kB/s]"
          }
        },
        "d784d619716e476dabb98077307cc40b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e505ec886442c68bbacd3af51388dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d036de785042789a161cebf872728b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "544995ebd611455b87512c58f627bc15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7c95500ea04e54ab8ea4eaaae786e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23620e53560f41ac95f62ec499eadd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead9a2635f5c49aba7e8181a7dded53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9609b2f8bbc42878297f1e91a0a7071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d054ef1e1ec746d5a4597136462cc287",
              "IPY_MODEL_df14b9fa9e6241c5827571af0fc7fe65",
              "IPY_MODEL_0a36b9801f0e44d792d19496ffd42636"
            ],
            "layout": "IPY_MODEL_338b2bf376ba452d879b89662cdec8ae"
          }
        },
        "d054ef1e1ec746d5a4597136462cc287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a891911154d4fe5ae623e65c460fca7",
            "placeholder": "​",
            "style": "IPY_MODEL_3311a7da240148a3b77df5dd8f533076",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "df14b9fa9e6241c5827571af0fc7fe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b66fce57f8b41279e3d8a05ea652012",
            "max": 797367631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02b556680878479c899edce11597260a",
            "value": 797367631
          }
        },
        "0a36b9801f0e44d792d19496ffd42636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97045b927b9b42c28e233dbc4c5dbaba",
            "placeholder": "​",
            "style": "IPY_MODEL_0048aba1bf19475280a02173aeeb037a",
            "value": " 797M/797M [00:28&lt;00:00, 27.2MB/s]"
          }
        },
        "338b2bf376ba452d879b89662cdec8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a891911154d4fe5ae623e65c460fca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3311a7da240148a3b77df5dd8f533076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b66fce57f8b41279e3d8a05ea652012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02b556680878479c899edce11597260a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97045b927b9b42c28e233dbc4c5dbaba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0048aba1bf19475280a02173aeeb037a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/small-language-models-fine-tuning/blob/main/domain-specific-small-language-models/05-generate-python-code/01_benchmark_inference_performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking Python Code Generation with Vanilla, ONNX Converted and Quantized CodeGen Models"
      ],
      "metadata": {
        "id": "ro2mCsr9wNoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "The code in this notebook is to benchmark inference performance (latency and throughtput) when generating Python code using a Vanilla [CodeGen](https://huggingface.co/Salesforce/codegen-350M-mono) 350M mono model, after ONNX conversion of the same model and after 8-bit quantization. It doesn't require hardware acceleration.  "
      ],
      "metadata": {
        "id": "cC6O6822XUOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the missing requirements in the ColabVM (only Optimum for the ONNX runtime)."
      ],
      "metadata": {
        "id": "uxm-Oc-FxRGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum[onnxruntime]==1.21.2"
      ],
      "metadata": {
        "id": "qBniEqbYvTsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the Transformers library to the latest version. A runtime restart is needed after."
      ],
      "metadata": {
        "id": "Lh5mdYf_V4Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers==4.44"
      ],
      "metadata": {
        "id": "Nh1Jwr5XQI4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "MjxKaxva1uUb",
        "outputId": "562ae8fe-83ba-4ad8-93b1-4df73908a0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.44.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vanilla Model"
      ],
      "metadata": {
        "id": "8Qgo8j3yAEC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the CodeGen 350 M mono model and its tokenizer from the HF's Hub."
      ],
      "metadata": {
        "id": "o3uieL3kxc-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "device = \"cpu\"\n",
        "model_id = \"Salesforce/codegen-350M-mono\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "oQXJ5wJJuMUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CodeGenForCausalLM\n",
        "\n",
        "model = CodeGenForCausalLM.from_pretrained(model_id).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "9JpoSzoHaOR4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "9abf88f516b847dda3279889f1a5adf8",
            "a4ba7126e2d541959dd99ac6583c6dac",
            "e3f1c1789ede47f4ac202c584520ca85",
            "c0632f863c514e5aa656973baa5da47f",
            "d784d619716e476dabb98077307cc40b",
            "a4e505ec886442c68bbacd3af51388dc",
            "74d036de785042789a161cebf872728b",
            "544995ebd611455b87512c58f627bc15",
            "8b7c95500ea04e54ab8ea4eaaae786e8",
            "23620e53560f41ac95f62ec499eadd73",
            "ead9a2635f5c49aba7e8181a7dded53e",
            "b9609b2f8bbc42878297f1e91a0a7071",
            "d054ef1e1ec746d5a4597136462cc287",
            "df14b9fa9e6241c5827571af0fc7fe65",
            "0a36b9801f0e44d792d19496ffd42636",
            "338b2bf376ba452d879b89662cdec8ae",
            "7a891911154d4fe5ae623e65c460fca7",
            "3311a7da240148a3b77df5dd8f533076",
            "6b66fce57f8b41279e3d8a05ea652012",
            "02b556680878479c899edce11597260a",
            "97045b927b9b42c28e233dbc4c5dbaba",
            "0048aba1bf19475280a02173aeeb037a"
          ]
        },
        "outputId": "271c935f-7f7b-4bca-98ba-8a489990d2b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9abf88f516b847dda3279889f1a5adf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/797M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9609b2f8bbc42878297f1e91a0a7071"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CodeGenForCausalLM(\n",
              "  (transformer): CodeGenModel(\n",
              "    (wte): Embedding(51200, 1024)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-19): 20 x CodeGenBlock(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): CodeGenAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        )\n",
              "        (mlp): CodeGenMLP(\n",
              "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=51200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set a text prompt (a Python function header) to be used across benchmarks."
      ],
      "metadata": {
        "id": "NlUHkMBOxtGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"def hello_world():\""
      ],
      "metadata": {
        "id": "_Euq2A50ANLW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code in the following cell is just to verify that model and tokenizer have been downloaded properly. You can skip its execution."
      ],
      "metadata": {
        "id": "2QIHUGmFx1EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=12)"
      ],
      "metadata": {
        "id": "3_AXjHFvaTO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(generated_ids[0],\n",
        "                       skip_special_tokens=True,\n",
        "                       pad_token_id=50256))"
      ],
      "metadata": {
        "id": "eqHYuC4PLX5u",
        "outputId": "f9152755-d5f0-4f1b-e785-d0349ae06907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def hello_world():\n",
            "    print(\"Hello World\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also pass a prompt in pure natural language."
      ],
      "metadata": {
        "id": "GDaP_JwPZjRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Create a bar chart with matplotlib\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=1000)"
      ],
      "metadata": {
        "id": "8_7dyXoDZbiE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(generated_ids[0],\n",
        "                       skip_special_tokens=True,\n",
        "                       pad_token_id=50256))"
      ],
      "metadata": {
        "id": "AG_aa2vIZdle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Create empty tensor with PyTorch\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=1000)"
      ],
      "metadata": {
        "id": "lQFSJgXSag4V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(generated_ids[0],\n",
        "                       skip_special_tokens=True,\n",
        "                       pad_token_id=50256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84zakgMqaoKg",
        "outputId": "8adf7cb0-8de8-42be-8512-aff5480a52a3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create empty tensor with PyTorch's default data type\n",
            "        \"\"\"\n",
            "        return torch.zeros(self.shape, dtype=torch.float32)\n",
            "\n",
            "    def __repr__(self):\n",
            "        \"\"\"\n",
            "        :return: String representation of the tensor\n",
            "        \"\"\"\n",
            "        return \"Tensor(shape={}, dtype={}, device={})\".format(self.shape, self.dtype, self.device)\n",
            "\n",
            "    def __len__(self):\n",
            "        \"\"\"\n",
            "        :return: Number of elements in the tensor\n",
            "        \"\"\"\n",
            "        return self.shape[0]\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        \"\"\"\n",
            "        :param index: Index of the element to retrieve\n",
            "        :return: The element at the given index\n",
            "        \"\"\"\n",
            "        return self.data[index]\n",
            "\n",
            "    def __setitem__(self, index, value):\n",
            "        \"\"\"\n",
            "        :param index: Index of the element to set\n",
            "        :param value: New value of the element\n",
            "        \"\"\"\n",
            "        self.data[index] = value\n",
            "\n",
            "    def __iter__(self):\n",
            "        \"\"\"\n",
            "        :return: Iterator over the elements of the tensor\n",
            "        \"\"\"\n",
            "        return iter(self.data)\n",
            "\n",
            "    def __add__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to add to the current tensor\n",
            "        :return: Sum of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return self.data + other\n",
            "\n",
            "    def __radd__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to add to the current tensor\n",
            "        :return: Sum of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return other + self.data\n",
            "\n",
            "    def __iadd__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to add to the current tensor\n",
            "        :return: Sum of the elements of the tensor\n",
            "        \"\"\"\n",
            "        self.data += other\n",
            "        return self\n",
            "\n",
            "    def __sub__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to subtract from the current tensor\n",
            "        :return: Difference of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return self.data - other\n",
            "\n",
            "    def __rsub__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to subtract from the current tensor\n",
            "        :return: Difference of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return other - self.data\n",
            "\n",
            "    def __isub__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to subtract from the current tensor\n",
            "        :return: Difference of the elements of the tensor\n",
            "        \"\"\"\n",
            "        self.data -= other\n",
            "        return self\n",
            "\n",
            "    def __mul__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to multiply to the current tensor\n",
            "        :return: Product of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return self.data * other\n",
            "\n",
            "    def __rmul__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to multiply to the current tensor\n",
            "        :return: Product of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return other * self.data\n",
            "\n",
            "    def __imul__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to multiply to the current tensor\n",
            "        :return: Product of the elements of the tensor\n",
            "        \"\"\"\n",
            "        self.data *= other\n",
            "        return self\n",
            "\n",
            "    def __truediv__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to divide by the current tensor\n",
            "        :return: Division of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return self.data / other\n",
            "\n",
            "    def __rtruediv__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to divide by the current tensor\n",
            "        :return: Division of the elements of the tensor\n",
            "        \"\"\"\n",
            "        return other / self.data\n",
            "\n",
            "    def __itruediv__(self, other):\n",
            "        \"\"\"\n",
            "        :param other: Tensor to divide by the current tensor\n",
            "        :return: Division of the elements of the tensor\n",
            "        \"\"\"\n",
            "        self.data /= other\n",
            "        return self\n",
            "\n",
            "    def __neg__(self):\n",
            "        \"\"\"\n",
            "        :return: Negated element of the tensor\n",
            "        \"\"\"\n",
            "        return -self.data\n",
            "\n",
            "    def __pos__(self):\n",
            "        \"\"\"\n",
            "        :return: Element of the tensor\n",
            "        \"\"\"\n",
            "        return +self\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Create a basic web app with Dash\n",
        "\"\"\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=1000)"
      ],
      "metadata": {
        "id": "RQRv_tytbGtV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(generated_ids[0],\n",
        "                       skip_special_tokens=True,\n",
        "                       pad_token_id=50256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jKcRNtSbQ4U",
        "outputId": "e17354d4-35e5-4eb3-e6b5-ca12fbf60ec3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Create a basic web app with Dash\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "import dash\n",
            "import dash_core_components as dcc\n",
            "import dash_html_components as html\n",
            "import plotly.express as px\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import plotly.graph_objects as go\n",
            "\n",
            "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
            "\n",
            "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
            "\n",
            "# Load the data\n",
            "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv')\n",
            "\n",
            "# Create the app layout\n",
            "app.layout = html.Div(children=[\n",
            "    html.H1('Gapminder Data', style={'textAlign': 'center'}),\n",
            "\n",
            "    dcc.Graph(\n",
            "        id='example-graph',\n",
            "        figure={\n",
            "            'data': [\n",
            "                go.Scatter(\n",
            "                    x=df['Year'],\n",
            "                    y=df['gdpPercap'],\n",
            "                    mode='lines+markers',\n",
            "                    name='Scatter'\n",
            "                ),\n",
            "                go.Scatter(\n",
            "                    x=df['Year'],\n",
            "                    y=df['lifeExp'],\n",
            "                    mode='lines+markers',\n",
            "                    name='Life expectancy'\n",
            "                ),\n",
            "                go.Scatter(\n",
            "                    x=df['Year'],\n",
            "                    y=df['gdpPercap'],\n",
            "                    mode='lines+markers',\n",
            "                    name='GDP per capita'\n",
            "                )\n",
            "            ],\n",
            "            'layout': go.Layout(\n",
            "                title={\n",
            "                    'text': 'Life Expectancy vs GDP per Capita',\n",
            "                    'y': 0.98,\n",
            "                    'x': 0.5,\n",
            "                    'xanchor': 'center',\n",
            "                    'yanchor': 'top'\n",
            "                },\n",
            "                xaxis={\n",
            "                    'title': 'Year',\n",
            "                    'rangeselector': {\n",
            "                        'buttons': list([\n",
            "                            {'count': 1, 'label': '1M', 'step': 'month', 'stepmode': 'backward'},\n",
            "                            {'count': 6, 'label': '6M', 'step': 'month', 'stepmode': 'backward'},\n",
            "                            {'step': 'all'}\n",
            "                        ])\n",
            "                    },\n",
            "                    'rangeslider': {\n",
            "                        'visible': True\n",
            "                    },\n",
            "                    'type': 'date'\n",
            "                },\n",
            "                yaxis={\n",
            "                    'title': 'Life Expectancy',\n",
            "                    'type': 'log'\n",
            "                },\n",
            "                legend={\n",
            "                    'x': 0,\n",
            "                    'y': 1,\n",
            "                    'bgcolor': 'rgba(255, 255, 255, 0)',\n",
            "                    'bordercolor': 'rgba(255, 255, 255, 0)'\n",
            "                },\n",
            "                margin={'l': 40, 'b': 40, 't': 10, 'r': 0}\n",
            "            )\n",
            "        }\n",
            "    )\n",
            "])\n",
            "\n",
            "# Callback function\n",
            "@app.callback(\n",
            "    [\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.dependencies.Output('example-graph', 'figure'),\n",
            "        dash.depend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also generate the body of a function, given only its definition."
      ],
      "metadata": {
        "id": "U2C58iZpbeAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "def increment_elements(int_list):\n",
        "  \"\"\"\n",
        "  Return list with elements incremented by 1\n",
        "  \"\"\"\n",
        "'''\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "generated_ids = model.generate(input_ids, max_length=1000)"
      ],
      "metadata": {
        "id": "EfbOn9VWbfF6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(generated_ids[0],\n",
        "                       skip_special_tokens=True,\n",
        "                       pad_token_id=50256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uiMFplbbvCd",
        "outputId": "70d5feec-095a-4a37-eb44-c7390ee91776"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def increment_elements(int_list):\n",
            "  \"\"\"\n",
            "  Return list with elements incremented by 1\n",
            "  \"\"\"\n",
            "  new_list = []\n",
            "  for i in int_list:\n",
            "    new_list.append(i + 1)\n",
            "  return new_list\n",
            "\n",
            "def test_increment_elements():\n",
            "  assert increment_elements([1,2,3]) == [1,3,4]\n",
            "  assert increment_elements([1,2,3,4,5]) == [1,3,5,7,9]\n",
            "  assert increment_elements([1,2,3,4,5,6]) == [1,3,6,10,15,20]\n",
            "\n",
            "def test_increment_elements_2():\n",
            "  assert increment_elements([1,2,3,4,5]) == [1,2,3,4,5,6]\n",
            "  assert increment_elements([1,2,3,4,5,6,7,8,9,10]) == [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
            "\n",
            "def test_increment_elements_3():\n",
            "  assert increment_elements([1,2,3,4,5,6]) == [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]\n",
            "  assert increment_elements([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]) == [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100]\n",
            "\n",
            "def test_increment_elements_4():\n",
            "  assert increment_elements([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup a Transformers' pipeline for inference with the Vanilla model."
      ],
      "metadata": {
        "id": "td1Nl5uUx_6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                pad_token_id=50256,\n",
        "                truncation=True,\n",
        "                max_length=500\n",
        "      )"
      ],
      "metadata": {
        "id": "HTBIqZ9MmF6P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the pipeline."
      ],
      "metadata": {
        "id": "K3x3oWkbyHFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "def increment_elements(int_list):\n",
        "  \"\"\"\n",
        "  Return list with elements incremented by 1\n",
        "  \"\"\"\n",
        "'''\n",
        "\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "p4NxE8a1m6xE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ec1463-6bdf-4120-e190-acfdff687852"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "def increment_elements(int_list):\n",
            "  \"\"\"\n",
            "  Return list with elements incremented by 1\n",
            "  \"\"\"\n",
            "  print(f\"Increasing {int_list} by 1\")\n",
            "  return int_list + 1\n",
            "# Run test\n",
            "first_int = 7\n",
            "second_int = 1\n",
            "third_int = 6\n",
            "increment_elements(first_int)\n",
            "increment_elements(second_int)\n",
            "print(first_int)\n",
            "increment_elements(third_int)\n",
            "print(second_int)\n",
            "print(third_int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"local-pt-checkpoint\")\n",
        "model.save_pretrained(\"local-pt-checkpoint\")"
      ],
      "metadata": {
        "id": "DIIsBPsmudM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc249ebf-7c1a-4191-d711-40dbad2b0a8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'do_sample': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some utils for benchmarking (more details about them in chapter 6 of the book)."
      ],
      "metadata": {
        "id": "q70kfNsKCeYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "from dataclasses import dataclass\n",
        "from time import perf_counter\n",
        "\n",
        "@contextmanager\n",
        "def track_infer_time(time_buffer):\n",
        "    start_time = perf_counter()\n",
        "    yield\n",
        "    end_time = perf_counter()\n",
        "\n",
        "    time_buffer.append(end_time - start_time)\n",
        "\n",
        "@dataclass\n",
        "class BenchmarkInferenceResult:\n",
        "    model_inference_time: [int]\n",
        "    optimized_model_path: str"
      ],
      "metadata": {
        "id": "pL77v2MCEhNx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a custom funtion to be reused across benchmarks with the different versions of the model under evaluation."
      ],
      "metadata": {
        "id": "il5ctRs0yU7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import trange\n",
        "\n",
        "def benchmark_inference(providers_dict, pipe, prompt, results):\n",
        "  for device, label in PROVIDERS:\n",
        "      for _ in trange(10, desc=\"Warming up\"):\n",
        "        pipe(prompt)\n",
        "\n",
        "      time_buffer = []\n",
        "      for _ in trange(100, desc=f\"Tracking inference time ({label})\"):\n",
        "        with track_infer_time(time_buffer):\n",
        "          pipe(prompt)\n",
        "\n",
        "      results[label] = BenchmarkInferenceResult(\n",
        "          time_buffer,\n",
        "          None\n",
        "      )\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "kROG4REwFO2d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the benchmarks for the CodeGen vanilla model."
      ],
      "metadata": {
        "id": "Y9-RNdkvyfQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "PROVIDERS = {\n",
        "    (\"cpu\", \"PyTorch CPU\"),\n",
        "}\n",
        "results = benchmark_inference(PROVIDERS, pipe, prompt, results)"
      ],
      "metadata": {
        "id": "dL9m9HtcFsP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c175ded3-5fe8-42ab-aebd-3218ad916e74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up: 100%|██████████| 10/10 [06:27<00:00, 38.71s/it]\n",
            "Tracking inference time (PyTorch CPU): 100%|██████████| 100/100 [1:05:22<00:00, 39.22s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ONNX Conversion"
      ],
      "metadata": {
        "id": "AHSowqvkAH2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent potential out of memory issues, let's delete the original model from memory."
      ],
      "metadata": {
        "id": "Ze83zNmcy0jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "sF_f0cr9HA6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb28c9a-84dc-47d6-e8c3-9a7ad2eac064"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the CodeGen 350M mono model using the Optimum package."
      ],
      "metadata": {
        "id": "v4ohyCiRy9uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from optimum.onnxruntime import ORTModelForCausalLM\n",
        "\n",
        "model_id = 'Salesforce/codegen-350M-mono'\n",
        "model = ORTModelForCausalLM.from_pretrained(model_id,\n",
        "                                            export=True,\n",
        "                                            provider=\"CPUExecutionProvider\",\n",
        "                                            )"
      ],
      "metadata": {
        "id": "FZciN9xVvUzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the converted model to disk."
      ],
      "metadata": {
        "id": "XPEzFKXFzGRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "onnx_path = Path(\"onnx\")\n",
        "model.save_pretrained(onnx_path)"
      ],
      "metadata": {
        "id": "biYmiE5e3h6Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup a pipeline for inference with the ONNX converted CodeGen 350M mono model."
      ],
      "metadata": {
        "id": "VJje5ki3zRnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                pad_token_id=50256,\n",
        "                truncation=True,\n",
        "                max_length=500\n",
        "                )"
      ],
      "metadata": {
        "id": "APwRbKX8anHK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the pipeline works."
      ],
      "metadata": {
        "id": "OWjihgZ7zYEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(prompt)\n",
        "result"
      ],
      "metadata": {
        "id": "e8wUQlWczdiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341811c4-8aa9-43fe-fbcd-8111dbc8fe22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '\\ndef increment_elements(int_list):\\n  \"\"\"\\n  Return list with elements incremented by 1\\n  \"\"\"\\n  for index, value in enumerate(int_list):\\n    value += 1\\n    int_list[index] = value\\n  return int_list\\n\\ndef sum_up_elements(sum_list):\\n  \"\"\"\\n  Return list with summed elements and sum is 0\\n  \"\"\"\\n  sum_list = map(lambda x: x + float(x), sum_list)\\n  sum_tuple = tuple(sum_list)\\n  sum_list.insert(0, 0.0)\\n  return sum_list, sum_tuple'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the benchmark on the ONNX converted model."
      ],
      "metadata": {
        "id": "aAanMvXczfCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROVIDERS = {\n",
        "    (\"CPUExecutionProvider\", \"ONNX CPU\"),\n",
        "}\n",
        "results = benchmark_inference(PROVIDERS, pipe, prompt, results)"
      ],
      "metadata": {
        "id": "OnPpHEKoIGxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054c3c59-e654-4ea9-ec05-271daa743239"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up: 100%|██████████| 10/10 [04:55<00:00, 29.52s/it]\n",
            "Tracking inference time (ONNX CPU): 100%|██████████| 100/100 [1:02:41<00:00, 37.62s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8-bit Quantization"
      ],
      "metadata": {
        "id": "NKlAIq_oz81N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent potential out of memory issues, let's delete the pipeline from memory."
      ],
      "metadata": {
        "id": "KESvr_wOzy7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del pipe\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "TQUAblExJWvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfbe1c9-3f20-430b-b24e-eec3c421f626"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4110"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do dynamic 8-bit quantization of the ONNX converted model and save it to disk."
      ],
      "metadata": {
        "id": "nijBTdmv0V41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from optimum.onnxruntime import ORTQuantizer\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "\n",
        "dynamic_quantizer = ORTQuantizer.from_pretrained(model)\n",
        "dqconfig = AutoQuantizationConfig.avx512_vnni(is_static=False,\n",
        "                                              per_channel=False)\n",
        "\n",
        "model_quantized_path = dynamic_quantizer.quantize(\n",
        "    save_dir=onnx_path,\n",
        "    quantization_config=dqconfig,\n",
        ")"
      ],
      "metadata": {
        "id": "YfM7NeIb2vqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c891545-4f82-4529-c0e4-6c0985a2f3af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating dynamic quantizer: QOperator (mode: IntegerOps, schema: u8/s8, channel-wise: False)\n",
            "Quantizing model...\n",
            "Saving quantized model at: onnx (external data format: False)\n",
            "Configuration saved in onnx/ort_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the quantized model in memory before setting the pipeline for it."
      ],
      "metadata": {
        "id": "yusDTLB00jXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model = ORTModelForCausalLM.from_pretrained(\"onnx\", file_name=\"model_quantized.onnx\")"
      ],
      "metadata": {
        "id": "3fBJg0ryPOnP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the pipeline for inference with the quantized model."
      ],
      "metadata": {
        "id": "gUosoY7N0o3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\",\n",
        "                model=quantized_model,\n",
        "                tokenizer=tokenizer,\n",
        "                pad_token_id=50256,\n",
        "                truncation=True,\n",
        "                max_length=500\n",
        "                )"
      ],
      "metadata": {
        "id": "6GQypqF7Qco_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the pipeline works as expected."
      ],
      "metadata": {
        "id": "gW0GqH1E17dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipe(prompt)\n",
        "result"
      ],
      "metadata": {
        "id": "ehBfVq_CQq28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ef8d05-f2ac-4355-dd09-899fbd0e35fd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '\\ndef increment_elements(int_list):\\n  \"\"\"\\n  Return list with elements incremented by 1\\n  \"\"\"\\n  for i in int_list:\\n    int_list[i] += 1\\n  return int_list\\n\\nprint(incdec_elements([\"a\", 2, \"b\"]))\\nprint(incdec_elements([1, \"a\", \"-b\"], ))\\nprint(incdec_elements([1, \"a\", \"\", \"-1\"], ))\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the benchmark on the quantized model."
      ],
      "metadata": {
        "id": "WGUi3AaYDC-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROVIDERS = {\n",
        "    (\"CPUExecutionProvider\", \"ONNX Quant CPU\"),\n",
        "}\n",
        "results = benchmark_inference(PROVIDERS, pipe, prompt, results)"
      ],
      "metadata": {
        "id": "l4cTBDxVIu4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26d4c14-f506-44a6-e1a3-efe1df5a0b40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up: 100%|██████████| 10/10 [03:42<00:00, 22.24s/it]\n",
            "Tracking inference time (ONNX Quant CPU): 100%|██████████| 100/100 [28:25<00:00, 17.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results of the Benchmarks"
      ],
      "metadata": {
        "id": "56NkSjpODGv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visually compare the average inference times across benchmarks for the 3 different versions of the model."
      ],
      "metadata": {
        "id": "8ak1DWKV2Y5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "# Compute average inference time\n",
        "time_results = {k: np.mean(v.model_inference_time) * 1e3 for k, v in results.items()}\n",
        "\n",
        "fig = px.bar(x=time_results.keys(), y=time_results.values(),\n",
        "             title=\"Average inference time (ms) for each provider\",\n",
        "             labels={'x':'Provider', 'y':'Avg Inference time (ms)'},\n",
        "             text_auto='.2s')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2QmZNhc4DMhq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "249a3f03-6f45-4398-d7db-2207daaab933"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7f6d3f06-acf6-489d-ae43-8cef4289e523\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7f6d3f06-acf6-489d-ae43-8cef4289e523\")) {                    Plotly.newPlot(                        \"7f6d3f06-acf6-489d-ae43-8cef4289e523\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Provider=%{x}\\u003cbr\\u003eAvg Inference time (ms)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2s}\",\"x\":[\"PyTorch CPU\",\"ONNX CPU\",\"ONNX Quant CPU\"],\"xaxis\":\"x\",\"y\":[39221.55142440994,37615.5228985698,17057.76590172998],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Provider\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Avg Inference time (ms)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Average inference time (ms) for each provider\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7f6d3f06-acf6-489d-ae43-8cef4289e523');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate latency and throughput metrics for the 3 benchmark sets and put them into a Pandas DataFrame."
      ],
      "metadata": {
        "id": "HgE7aBCb2l32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_results = {k: np.mean(v.model_inference_time) * 1e3 for k, v in results.items()}\n",
        "time_results_std = {k: np.std(v.model_inference_time) * 1000 for k, v in results.items()}"
      ],
      "metadata": {
        "id": "fOsjKpmlK_PQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perf_results = {}\n",
        "for k, v in results.items():\n",
        "  latency_list = v.model_inference_time\n",
        "  latency_50 = np.percentile(latency_list, 50) * 1e3\n",
        "  latency_75 = np.percentile(latency_list, 75) * 1e3\n",
        "  latency_90 = np.percentile(latency_list, 90) * 1e3\n",
        "  latency_95 = np.percentile(latency_list, 95) * 1e3\n",
        "  latency_99 = np.percentile(latency_list, 99) * 1e3\n",
        "\n",
        "  average_latency = np.mean(v.model_inference_time) * 1e3\n",
        "  throughput = 1 * (1000 / average_latency)\n",
        "\n",
        "  perf_results[k] = (\n",
        "        average_latency,\n",
        "        latency_50,\n",
        "        latency_75,\n",
        "        latency_90,\n",
        "        latency_95,\n",
        "        latency_99,\n",
        "        throughput,\n",
        "    )"
      ],
      "metadata": {
        "id": "Uao1a7ALLAP6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "index_labels = ['Average_latency (ms)', 'Latency_P50', 'Latency_P75',\n",
        "                'Latency_P90', 'Latency_P95', 'Latency_P99', 'Throughput']\n",
        "perf_df = pd.DataFrame(data=perf_results, index=index_labels)\n",
        "perf_df"
      ],
      "metadata": {
        "id": "P5AMItfgMQMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "80ff56b9-292f-44b5-9366-573502d8fb07"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       PyTorch CPU      ONNX CPU  ONNX Quant CPU\n",
              "Average_latency (ms)  39221.551424  37615.522899    17057.765902\n",
              "Latency_P50           32732.477330  27171.710279    11113.889900\n",
              "Latency_P75           64431.931898  70561.306100    29230.478066\n",
              "Latency_P90           77617.432435  71551.577962    37607.597394\n",
              "Latency_P95           78955.183386  71858.288423    37766.399730\n",
              "Latency_P99           82057.127682  74111.910064    40044.424899\n",
              "Throughput                0.025496      0.026585        0.058624"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b843a10d-4a8e-4572-9fcb-bb5b3d9ff45f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PyTorch CPU</th>\n",
              "      <th>ONNX CPU</th>\n",
              "      <th>ONNX Quant CPU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Average_latency (ms)</th>\n",
              "      <td>39221.551424</td>\n",
              "      <td>37615.522899</td>\n",
              "      <td>17057.765902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency_P50</th>\n",
              "      <td>32732.477330</td>\n",
              "      <td>27171.710279</td>\n",
              "      <td>11113.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency_P75</th>\n",
              "      <td>64431.931898</td>\n",
              "      <td>70561.306100</td>\n",
              "      <td>29230.478066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency_P90</th>\n",
              "      <td>77617.432435</td>\n",
              "      <td>71551.577962</td>\n",
              "      <td>37607.597394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency_P95</th>\n",
              "      <td>78955.183386</td>\n",
              "      <td>71858.288423</td>\n",
              "      <td>37766.399730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latency_P99</th>\n",
              "      <td>82057.127682</td>\n",
              "      <td>74111.910064</td>\n",
              "      <td>40044.424899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Throughput</th>\n",
              "      <td>0.025496</td>\n",
              "      <td>0.026585</td>\n",
              "      <td>0.058624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b843a10d-4a8e-4572-9fcb-bb5b3d9ff45f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b843a10d-4a8e-4572-9fcb-bb5b3d9ff45f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b843a10d-4a8e-4572-9fcb-bb5b3d9ff45f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-abae4f10-2ffa-40dc-8270-64ec7d54f301\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abae4f10-2ffa-40dc-8270-64ec7d54f301')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-abae4f10-2ffa-40dc-8270-64ec7d54f301 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cba76d67-4788-44b1-b166-b6de4c54b4b3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('perf_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cba76d67-4788-44b1-b166-b6de4c54b4b3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('perf_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "perf_df",
              "summary": "{\n  \"name\": \"perf_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"PyTorch CPU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30719.176832614747,\n        \"min\": 0.025496186756591165,\n        \"max\": 82057.12768162937,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          39221.55142440994,\n          32732.477330499933,\n          82057.12768162937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ONNX CPU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29211.108749827974,\n        \"min\": 0.026584769343669594,\n        \"max\": 74111.91006405877,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          37615.5228985698,\n          27171.710278998944,\n          74111.91006405877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ONNX Quant CPU\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15526.245589775348,\n        \"min\": 0.05862432429668771,\n        \"max\": 40044.42489896023,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          17057.76590172998,\n          11113.889900499998,\n          40044.42489896023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visually compare inference durations across benchmarks for the 3 different versions of the model."
      ],
      "metadata": {
        "id": "LOFMzIya283h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(columns=['Provider', 'Inference_time'])\n",
        "for k, v in results.items():\n",
        "  for i in range(len(v.model_inference_time)):\n",
        "    results_df.loc[len(results_df.index)] = [k, v.model_inference_time[i] * 1e3]\n",
        "\n",
        "fig = px.box(results_df, x=\"Provider\", y=\"Inference_time\",\n",
        "             points=\"all\",\n",
        "             labels={'Provider':'Provider', 'Inference_time':'Inference durations (ms)'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "22IhNSXGPcfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "47045c30-333e-409e-e225-f4ca618b7778"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"84bb9a76-bc98-4096-866e-c1cdaa655d48\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"84bb9a76-bc98-4096-866e-c1cdaa655d48\")) {                    Plotly.newPlot(                        \"84bb9a76-bc98-4096-866e-c1cdaa655d48\",                        [{\"alignmentgroup\":\"True\",\"boxpoints\":\"all\",\"hovertemplate\":\"Provider=%{x}\\u003cbr\\u003eInference durations (ms)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"PyTorch CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\",\"ONNX Quant CPU\"],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[24324.545870999827,13331.418964000477,55498.62174699956,75455.42736000061,8285.129994999807,63956.67670700004,75697.06361899989,17748.425942999347,1989.0105060003407,77211.6114139999,75447.02237999991,79286.40361399994,38333.08798500002,32327.12115100003,14067.238570999507,37019.689615999596,75845.35096699983,7094.917409000118,26000.496523000038,12245.16705699989,18494.15443900034,25113.413191999825,10481.73948099975,61638.505472999896,18052.304816999822,10422.897751000164,6104.63001700009,49897.700319999785,3750.675143999615,77676.84943800032,78503.9037890001,7069.333946999905,19017.028506000315,28588.539263999337,61446.8000779998,77735.23034899973,76909.0626569996,8197.930297999847,15374.572177000118,33137.83350999984,77840.83429900056,74447.4930030001,77610.83054599931,21296.065015999375,14205.344981000053,43897.96169700003,78937.75074199948,76646.66298000066,33774.314457999935,9146.473497000443,64239.6210400002,20860.053855999467,15200.149397999667,81475.69091500009,82050.14524799935,82748.38861100034,31622.19754600119,14273.989418999918,81064.3237029999,19284.240357999806,25461.705845000324,64643.110582999725,9901.893295000264,9886.380768999516,5495.647512001597,56462.49618500042,26954.436342999543,64440.399601000536,23511.756130999856,57131.92378599888,35839.51083800093,4955.491463000726,14258.985438000309,9235.363773001154,13742.798072998994,27165.48103799869,54555.77316999916,26990.1966669986,73758.04943600087,19513.83042499947,76818.8556240002,12236.75712899967,63963.814779999666,9321.653564000371,34421.51817800004,51072.52589199925,15201.740964999772,38699.08234799914,76551.79179900006,39198.15387299968,49353.015983999285,35142.589731000044,20217.568033000134,64052.07809499916,68463.98939500068,64429.10932999985,5217.984061999232,13924.159516000145,22392.509403000076,38170.95101000086,11229.351695999867,12684.372274999987,71653.84379500028,71220.74301999965,37088.892997000585,12777.916466000534,9848.916394999833,5147.789499000282,43133.670844001244,20593.028060000506,74076.19332299873,5960.923610999089,22682.897312999557,70556.45725900104,7055.879113000628,8223.061969998525,45336.378641999545,71852.81361000125,7404.559412998424,13288.725856999008,3591.6328630009957,71007.13540700053,71146.55151000079,19209.066994999375,5434.798906000651,3094.0561429997615,70905.35160599939,61456.92015699933,26273.05926199915,22358.56131699984,13897.86556099898,68991.64293300055,70575.8526210011,48749.72260599861,13486.220648999733,25000.888556000064,71827.12252999954,20859.357887999067,70854.571029,23568.047221000597,26308.61580599958,72180.33549499887,13163.875470998391,70611.10845000076,11485.824804000003,35033.43876500003,46381.09404699935,18350.057493998975,61805.649280999205,16469.11262299909,71962.30986499904,42280.702516998645,24715.3576540004,72038.01058099998,43631.98628200007,71296.37835100039,70621.11122700117,24511.104085000625,16637.772637001035,47001.94450499839,16293.61058699942,10568.800922999799,61089.80519800025,71643.32051800011,26931.46734599941,12015.881970999544,71378.54697999865,11543.156981999346,37860.63069800002,71703.06518800135,17739.334367000993,17448.65405500059,24946.094078999522,7505.868977999853,11773.108518998924,71101.08225899967,70992.60226700062,26416.326446000312,50780.27090699834,33460.59877800144,71484.67043299752,59035.149026,77647.86742900105,2142.2318929980975,19809.959579997667,30115.170332999696,11510.168822002015,19643.161460000556,70065.49843700122,11419.027659001586,70325.85543999812,27411.95321199848,6272.479638999357,31597.617462997732,21356.499362998875,45889.906794000126,71541.38434499691,71098.12532700016,48578.63836999968,10824.06692800214,7463.574869001604,4835.242956000002,3135.795815000165,31753.79285300005,30315.329246001056,36830.237352998665,3910.9772730007535,25671.446393000224,37058.28303400267,5157.028047997301,4028.913170997839,12904.714002997935,10692.109379000613,10091.588593000779,5628.418218999286,36690.193422997254,23311.75058000008,1367.2338019969175,6511.758762000682,2630.1454409986036,37480.53094699935,37258.78055499925,4253.09610000113,44205.05067200065,1835.5580679999548,10607.626364999305,5714.335295997444,23378.202628002327,3724.699116002739,28954.227597998397,1396.317493999959,1026.501411000936,39205.31771499736,37941.1218009991,8645.198557002004,5457.752723999874,6309.522174000449,18595.97286999997,7951.06443899931,5654.3544929991185,35146.08006200069,2709.1738849994726,27788.11183200014,37565.98132900035,15516.918106000958,37630.41505300134,13687.06303900035,32235.77540900078,8106.391544999497,5890.860359999351,7858.235992996924,20662.011060001532,21160.98405199955,37655.84820400181,1774.643966997246,12742.030262001208,30059.229468999547,5875.254243001109,20214.264630001708,10466.174871999101,27425.900182999612,40002.3983760002,10147.522279999976,7927.483356001176,15211.8838589995,4184.162868998101,32056.867389001127,22498.490956997557,16677.141180000035,4217.117649001011,37606.67596699932,6688.732085000083,16549.57211600049,6324.223904000974,37615.890233002574,7151.415394000651,26251.96253700051,37839.05419399889,3380.609943997115,4064.839327998925,7632.902738001576,7801.167659999919,17562.374684999668,21853.031255999667,18834.060484001384,37589.330875001906,37762.575811000715,8049.79867899965,1771.6039410006488,10120.985004999966,5936.498636001488,3605.7802569994237,6174.204130002181,37513.086929000565,11535.670421999384,6843.28998500132,37670.256094999786,5528.342819001409,15603.422622996732,28237.051734999113],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Provider\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Inference durations (ms)\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('84bb9a76-bc98-4096-866e-c1cdaa655d48');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}