{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/small-language-models-fine-tuning/blob/main/hands-on-llm-fine-tuning-with-pytorch-and-huggingface/01_loading_quantized_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYLXKf47cotm"
      },
      "source": [
        "## Chapter 2: Loading a Quantized Model"
      ],
      "id": "NYLXKf47cotm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sbYPOA0cotp"
      },
      "source": [
        "### Spoilers\n",
        "\n",
        "In this chapter, we’ll:\n",
        "\n",
        "- Understand how quantization works\n",
        "- Explore the pros and cons of using different data types (FP16, BF16, FP32)\n",
        "- Introduce the concept of mixed-precision computing\n",
        "- Use BitsAndBytes to quantize a pretrained model while loading it"
      ],
      "id": "5sbYPOA0cotp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMAZGnxLcotp"
      },
      "source": [
        "### Setup"
      ],
      "id": "bMAZGnxLcotp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kODUm5BmEQhI"
      },
      "outputs": [],
      "source": [
        "# If you're running on Colab\n",
        "!pip install datasets bitsandbytes trl"
      ],
      "id": "kODUm5BmEQhI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH-5DqVPcotr"
      },
      "outputs": [],
      "source": [
        "# If you're running on runpod.io's Jupyter Template\n",
        "#!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib"
      ],
      "id": "YH-5DqVPcotr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF5_Qir0cotr"
      },
      "source": [
        "### Imports"
      ],
      "id": "LF5_Qir0cotr"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j2CPDad7cots"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from accelerate import init_empty_weights\n",
        "from accelerate.utils.modeling import find_tied_parameters, get_mixed_precision_context_manager\n",
        "from accelerate.utils.operations import convert_outputs_to_fp32\n",
        "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4, LinearNF4\n",
        "from collections import Counter\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
        "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
        "from types import MethodType\n",
        "from matplotlib import pyplot as plt"
      ],
      "id": "j2CPDad7cots"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxctCF0ucots"
      },
      "source": [
        "### The Goal\n",
        "\n",
        "We quantize models to reduce their memory footprint. We can easily shrink the model’s size to a quarter or an eighth of its original size. Keep in mind, however, that the more a model is quantized (i.e., the fewer bit used\n",
        "to represent its weights), the more likely its performance will be negatively affected."
      ],
      "id": "zxctCF0ucots"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ZPL7f_cott"
      },
      "source": [
        "### Pre-Reqs\n",
        "\n",
        "| Type | Name | # bits | Nickname |\n",
        "|---|---|---|---|\n",
        "| FP32 | Floating Point | 32 | Full Precision |\n",
        "| BF16 | Brain Float | 16 | Half-Precision |\n",
        "| FP16 | Floating Point | 16 | Half-Precision |\n",
        "| INT8 | Integer | 8 | 8-bit Quantized |\n",
        "| FP4 | Floating Point | 4 | 4-bit Quantized |\n",
        "| NF4 | Normal Float | 4 | 4-bit Quantized |\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_sizes.png?raw=True)\n",
        "<center>Figure 2.1 - Data type’s size comparison</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/model_sizes.png?raw=True)\n",
        "<center>Figure 2.2 - Representing the same model using different data types</center>"
      ],
      "id": "d4ZPL7f_cott"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP1DVuR8cotu"
      },
      "source": [
        "### Quantization in a Nutshell"
      ],
      "id": "xP1DVuR8cotu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole idea is actually quite simple, and it’s pretty much the same as building a histogram.\n",
        "\n",
        "Let’s go over a practical example. Say that you have 1,000 weights in the -0.2 to 0.2 range"
      ],
      "metadata": {
        "id": "0Suqb1gOeLTK"
      },
      "id": "0Suqb1gOeLTK"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bk8HVOutcotu",
        "outputId": "2d9ffa0b-d761-457e-9cbc-c34fdcfa2548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.2066), tensor(0.2097))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "weights = torch.randn(1000) * .07\n",
        "weights.min(), weights.max()"
      ],
      "id": "bk8HVOutcotu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say you choose to use four bins only."
      ],
      "metadata": {
        "id": "YxfcwI50fCeZ"
      },
      "id": "YxfcwI50fCeZ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KlVUKyB6cotv",
        "outputId": "58ffd90e-24e2-499a-b0ab-c20aed99172b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]), tensor(0.1041))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "n_bins = 4\n",
        "bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "bin_width = bins[1]-bins[0]\n",
        "bins, bin_width"
      ],
      "id": "KlVUKyB6cotv"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nrDixnBYcotw",
        "outputId": "47c2d622-625a-4194-fa11-27b7c4a23f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(weights, bins=bins)\n",
        "ax.set_xlabel('Values')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "nrDixnBYcotw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compute the bin indexes for each weight."
      ],
      "metadata": {
        "id": "eKzQwAO_fjMU"
      },
      "id": "eKzQwAO_fjMU"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Db6spEdRcotw",
        "outputId": "2547ca7d-2325-4186-946b-dfc504696edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n",
            "tensor([1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "print(weights[:20])\n",
        "print(bin_indexes[:20])"
      ],
      "id": "Db6spEdRcotw"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H_ZmN2yZcotw",
        "outputId": "cf981bcb-2e14-402e-c3ca-bdd5d2f5a9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(bin_indexes, bins=np.arange(n_bins+1)-.5)\n",
        "ax.set_xticks([0, 1, 2, 3])\n",
        "ax.set_xlabel('Bin Indexes')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "H_ZmN2yZcotw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef90ki3Rcotw"
      },
      "source": [
        "The number of bins you choose and the number of bits required to represent it are related to each other\n",
        "through the following expression:\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{n_bins}=2^{\\text{n_bits}} \\implies \\text{n_bits} = \\log_2({\\text{n_bins}})\n",
        "$$\n",
        "\n",
        "<center>Equation 2.1 - Number of bits vs number of bins</center>"
      ],
      "id": "Ef90ki3Rcotw"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NASieePAcotw",
        "outputId": "f4ca4a86-ddd7-4b58-e846-88ff454a69a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "bin_values = bins[:-1]\n",
        "first_bin = bin_values[0]\n",
        "bin_values"
      ],
      "id": "NASieePAcotw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqSN68KDcotx"
      },
      "source": [
        "To retrieve the (approximate) original values, we\n",
        "don’t even need to use it as a lookup table; we can simply use the following expression:\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{approx_value} = \\text{bin_index} * \\text{bin_width} + \\text{first_bin}\n",
        "$$\n",
        "\n",
        "<center>Equation 2.2 - Retrieving the (approximate) original value</center>"
      ],
      "id": "yqSN68KDcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s apply the expression above to the full range of bin indexes to double-check it works properly:"
      ],
      "metadata": {
        "id": "aY1SsDBMhEsv"
      },
      "id": "aY1SsDBMhEsv"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ezU4I6Gucotx",
        "outputId": "9c26b69f-0dca-4106-adfb-a57f574cf74c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.arange(0, n_bins) * bin_width + first_bin"
      ],
      "id": "ezU4I6Gucotx"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OKbEMdkOcotx",
        "outputId": "8a3d9fba-c348-40df-c23a-0533c0b8103e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066,  0.0015, -0.1026,\n",
            "        -0.1026, -0.1026,  0.1056, -0.1026,  0.0015,  0.0015, -0.1026, -0.1026,\n",
            "         0.0015,  0.1056, -0.2066, -0.2066])\n"
          ]
        }
      ],
      "source": [
        "approx_values = bin_indexes * bin_width + first_bin\n",
        "print(approx_values[:20])"
      ],
      "id": "OKbEMdkOcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compare the approximate values to the original values:"
      ],
      "metadata": {
        "id": "YP8qCZQJhKma"
      },
      "id": "YP8qCZQJhKma"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xB-zlzPdcotx",
        "outputId": "20b7ae1a-8cd0-4e9a-b37b-a2e91bb4332b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n"
          ]
        }
      ],
      "source": [
        "print(weights[:20])"
      ],
      "id": "xB-zlzPdcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s kind of a crude approximation, isn’t it?\n",
        "\n",
        "We can have a better idea of how bad it really is by computing the\n",
        "root mean squared error (RMSE) as if the quantized values were \"predictions\" and the original values were\n",
        "\"targets.\""
      ],
      "metadata": {
        "id": "6tJ98kKYhhHt"
      },
      "id": "6tJ98kKYhhHt"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yGkhVvurcotx",
        "outputId": "344bbbaa-db54-4a94-a47f-2a492f25bb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0615)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "mse_fn = nn.MSELoss()\n",
        "mse_fn(approx_values, weights).sqrt()"
      ],
      "id": "yGkhVvurcotx"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "E6LkEECHcoty"
      },
      "outputs": [],
      "source": [
        "def quantize(weights, n_bits=8):\n",
        "    assert n_bits <= 16, \"Using more bits may very slow execution and/or crashing.\"\n",
        "    n_bins = 2**n_bits\n",
        "    bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "    first_bin = bins[0]\n",
        "    bin_width = bins[1]-bins[0]\n",
        "    bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "    return bin_indexes, bin_width, first_bin\n",
        "\n",
        "def dequantize(bin_indexes, bin_width, first_bin):\n",
        "    approx_values = bin_indexes * bin_width + first_bin\n",
        "    return approx_values"
      ],
      "id": "E6LkEECHcoty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s try comparing the RMSE of several quantization choices:"
      ],
      "metadata": {
        "id": "QBZN4AithvjF"
      },
      "id": "QBZN4AithvjF"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cazt5adQcoty",
        "outputId": "d36e2529-5ead-48e0-8933-19d4d5348fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-bit Quantization:\n",
            "Approximation value: tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.06153079494833946\n",
            "\n",
            "\n",
            "4-bit Quantization:\n",
            "Approximation value: tensor([-0.0505,  0.0535, -0.0505,  0.0015, -0.0245, -0.1286])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.01522719394415617\n",
            "\n",
            "\n",
            "8-bit Quantization:\n",
            "Approximation value: tensor([-0.0359,  0.0714, -0.0261,  0.0080, -0.0131, -0.1058])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.0009653186425566673\n",
            "\n",
            "\n",
            "16-bit Quantization:\n",
            "Approximation value: tensor([-0.0359,  0.0718, -0.0248,  0.0085, -0.0128, -0.1049])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.00014281623589340597\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n_bits in [2, 4, 8, 16]:\n",
        "    res = quantize(weights, n_bits=n_bits)\n",
        "    approx_values = dequantize(*res)\n",
        "    print(f'{n_bits}-bit Quantization:')\n",
        "    print(f\"Approximation value: {approx_values[:6]}\")\n",
        "    print(f\"Original value: {weights[:6]}\")\n",
        "    print(f\"MSE value: {mse_fn(approx_values, weights).sqrt()}\")\n",
        "    print('\\n')"
      ],
      "id": "cazt5adQcoty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the numbers above, 16-bit quantization looks pretty good, right?\n",
        "\n",
        "Using 16 bits for quantization means\n",
        "having 65,536 bins. That’s a lot of bins! However, there’s a better way to use 16 bits: we can simply cast our\n",
        "weights down to 16-bit floating-point (FP16) numbers, often referred to as half-precision."
      ],
      "metadata": {
        "id": "U3HwnG_7jOXz"
      },
      "id": "U3HwnG_7jOXz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQJlD4Gncoty"
      },
      "source": [
        "****\n",
        "**ASIDE: Weight Distribution of Phi-3's Linear Layers**\n",
        "\n",
        "The following plots show the weight distribution of a large linear layer, `qkv_proj`, within the self-\n",
        "attention block in Phi-3. Other layers, such as `o_proj`, also located within the self-attention block, and\n",
        "`gate_up_proj` and `down_proj`, in the MLP block, have very similar weight distributions. This layer is\n",
        "present in every one of the 32 decoder blocks (indicated by the number in square brackets). You’ll notice\n",
        "that these millions of weights are concentrated within a very narrow range. But there are a few outliers as\n",
        "well, so each subplot also contains the actual range of observed weights in the corresponding layer.\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/self_attn.qkv_proj.png?raw=True)\n",
        "<center>Figure 2.5 - Weight distribution of Phi-3 layers</center>\n",
        "\n",
        "****"
      ],
      "id": "WQJlD4Gncoty"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_oOMPsBcoty"
      },
      "source": [
        "### Half-Precision Weights"
      ],
      "id": "p_oOMPsBcoty"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oy6UvZ6Bcoty",
        "outputId": "ef2e1f9e-7b39-4822-fdd8-b26e86bdb88f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048],\n",
            "       dtype=torch.float16)\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n"
          ]
        }
      ],
      "source": [
        "fp16_weights = weights.to(torch.float16)\n",
        "print(fp16_weights[:6])\n",
        "print(weights[:6])"
      ],
      "id": "Oy6UvZ6Bcoty"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1aU8riUEcoty",
        "outputId": "22a017a4-95d1-4180-eafd-74d9b44b4fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4244e-05)\n"
          ]
        }
      ],
      "source": [
        "print(mse_fn(fp16_weights, weights).sqrt())"
      ],
      "id": "1aU8riUEcoty"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d__tBPH2coty"
      },
      "source": [
        "#### Living on the Edge"
      ],
      "id": "d__tBPH2coty"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "imfkQHmFcoty",
        "outputId": "87585539-8437-46f2-ae43-0bf8b8082f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8526e-16)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "torch.manual_seed(14)\n",
        "tiny_values = torch.randn(1000)*1e-5\n",
        "fp16_tiny_values = tiny_values.to(torch.float16)\n",
        "mse_fn(fp16_tiny_values, tiny_values)"
      ],
      "id": "imfkQHmFcoty"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jG6eoIgBcoty",
        "outputId": "bab5c015-60cc-476d-9914-50a4470f677e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.7241e-06,  1.1441e-05,  3.7199e-06, -1.1252e-06, -2.4735e-08])\n",
            "tensor([-2.7418e-06,  1.1444e-05,  3.6955e-06, -1.1325e-06, -0.0000e+00],\n",
            "       dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "print(tiny_values[155:160])\n",
        "print(fp16_tiny_values[155:160])"
      ],
      "id": "jG6eoIgBcoty"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IWKLVldNcoty",
        "outputId": "e05a44bb-94ac-4d03-d0b8-9be507a378b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([155074.0938,  64881.6602,   2729.5815, -40790.6562,  68846.7188])\n",
            "tensor([    inf,  64896.,   2730., -40800.,     inf], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(19)\n",
        "large_values = torch.randn(1000)*1e5\n",
        "fp16_large_values = large_values.to(torch.float16)\n",
        "print(large_values[:5])\n",
        "print(fp16_large_values[:5])"
      ],
      "id": "IWKLVldNcoty"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JvbihBFmcotz",
        "outputId": "f952f76e-9e67-4c13-b324-824d674c7c18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "fp16_info = torch.finfo(torch.float16)\n",
        "fp16_info"
      ],
      "id": "JvbihBFmcotz"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iH6qElWPcotz",
        "outputId": "0ddde951-fe82-4247-df3c-db23b2cea8b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.960464477539063e-08"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "smallest_subnormal = fp16_info.smallest_normal * 2**-10\n",
        "smallest_subnormal"
      ],
      "id": "iH6qElWPcotz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqqT8zpcot0"
      },
      "source": [
        "### The Brain Float"
      ],
      "id": "adqqT8zpcot0"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sCND_3pocot0",
        "outputId": "58bb1c2f-bcc2-4024-9803-57fa2e363c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n",
            "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n"
          ]
        }
      ],
      "source": [
        "bf16_info = torch.finfo(torch.bfloat16)\n",
        "print(bf16_info)\n",
        "print(fp16_info)"
      ],
      "id": "sCND_3pocot0"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MvIMEreGcot0",
        "outputId": "cc3abb36-be06-4573-8ec2-c3ae51eaa616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "fp32_info = torch.finfo(torch.float32)\n",
        "fp32_info"
      ],
      "id": "MvIMEreGcot0"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "skNlGbnKcot0",
        "outputId": "751f329f-cac0-4d63-88fd-497cb8a5d608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.555555582])\n",
            "tensor([0.555664062], dtype=torch.float16)\n",
            "tensor([0.554687500], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([0.555555555])\n",
        "torch.set_printoptions(precision=9)\n",
        "print(x)\n",
        "print(x.to(torch.float16))\n",
        "print(x.to(torch.bfloat16))\n",
        "torch.set_printoptions(precision=4)"
      ],
      "id": "skNlGbnKcot0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx0cNj4Rcot0"
      },
      "source": [
        "|Type | Precision | Sub-normal | Min. | Max. |\n",
        "|---|---|---|---|---|\n",
        "|FP32 | e-08 | e-45 | e-38 | e+38 |\n",
        "|BF16 | e-03  | NA | e-38 | e+38 |\n",
        "|FP16 | e-04  | e-08  | e-05 | e+04 |"
      ],
      "id": "tx0cNj4Rcot0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcvI696kcouF"
      },
      "source": [
        "### Loading Models\n",
        "\n",
        "****\n",
        "**Summary of \"Loading Models\"**\n",
        "- if supported by your GPU, use `torch.bfloat16` instead of `torch.float16` for all things 16-bit\n",
        " ```python\n",
        " supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        " dtypes16 = (torch.bfloat16 if supported else torch.float16)\n",
        " ```\n",
        "- when loading a pretrained model, always specify its `torch_dype` upfront\n",
        " ```python\n",
        " model = AutoModelForCausalLM.from_pretrained(repo_id, device_map='cuda:0', torch_dtype=torch.float32)\n",
        " ```\n",
        "****"
      ],
      "id": "AcvI696kcouF"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oI5TgC2bcouF"
      },
      "outputs": [],
      "source": [
        "def get_parm_dtypes(iterable, top_k=3):\n",
        "    return Counter([p.dtype for p in iterable]).most_common(top_k)"
      ],
      "id": "oI5TgC2bcouF"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rG0qr1fycouI",
        "outputId": "18f2992b-a0a2-46fa-a299-cddc1900299e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324.785664\n",
            "[(torch.float32, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", device_map='cuda:0')\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "rG0qr1fycouI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s download the model’s .bin file containing the\n",
        "pretrained weights."
      ],
      "metadata": {
        "id": "SDPV3dyj2exv"
      },
      "id": "SDPV3dyj2exv"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xf1Krw-icouI",
        "outputId": "fea1c4a3-464a-422a-9a41-7f904b2e26b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-26 05:19:33--  https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.23, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/627b73032a9ac271ba208904/76eaeb9dc3fdd8890e49879c311a88ea5843a8aba2992a409b7b16c43a6aa92b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251226T051933Z&X-Amz-Expires=3600&X-Amz-Signature=c142ab852f95ade52105ea7102b678fd6a6faf3881b2dcf1ffbb13420efa626c&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1766729973&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjcyOTk3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjdiNzMwMzJhOWFjMjcxYmEyMDg5MDQvNzZlYWViOWRjM2ZkZDg4OTBlNDk4NzljMzExYTg4ZWE1ODQzYThhYmEyOTkyYTQwOWI3YjE2YzQzYTZhYTkyYioifV19&Signature=JzFpy3-XgtYgBcaw6RnVFG7YCLMA0DAqvtejQo80k%7E-ezKbpmG0uAgw35x9Z9kq1EWzZtN5qJypPZXA1bC-IVzsg0yGZ1TVPTuhunIb6uF5HcK%7EOCQYn2evEOOA2trIjcqvBerfgsQ4MZ8NjUVpw%7EJ6V2peFOooTNI0wd8Fy6lblmHOvw%7EWM1LUl2ZLLPsPzhYS8uCsW21oCXKdOH7yxSLNYkUBuTHghyLi78Kd5derthuwqXhNFXLBFLqxq7y9WCXtGP-FK9B9aoF35hHQrsWzJRVafuDbyXm0IP0zNANT82fPIxceEffzldzzAQsCbTF1yrJJuD1RzU%7ERF8rG4pg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-26 05:19:33--  https://cas-bridge.xethub.hf.co/xet-bridge-us/627b73032a9ac271ba208904/76eaeb9dc3fdd8890e49879c311a88ea5843a8aba2992a409b7b16c43a6aa92b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251226%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251226T051933Z&X-Amz-Expires=3600&X-Amz-Signature=c142ab852f95ade52105ea7102b678fd6a6faf3881b2dcf1ffbb13420efa626c&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1766729973&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjcyOTk3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjdiNzMwMzJhOWFjMjcxYmEyMDg5MDQvNzZlYWViOWRjM2ZkZDg4OTBlNDk4NzljMzExYTg4ZWE1ODQzYThhYmEyOTkyYTQwOWI3YjE2YzQzYTZhYTkyYioifV19&Signature=JzFpy3-XgtYgBcaw6RnVFG7YCLMA0DAqvtejQo80k%7E-ezKbpmG0uAgw35x9Z9kq1EWzZtN5qJypPZXA1bC-IVzsg0yGZ1TVPTuhunIb6uF5HcK%7EOCQYn2evEOOA2trIjcqvBerfgsQ4MZ8NjUVpw%7EJ6V2peFOooTNI0wd8Fy6lblmHOvw%7EWM1LUl2ZLLPsPzhYS8uCsW21oCXKdOH7yxSLNYkUBuTHghyLi78Kd5derthuwqXhNFXLBFLqxq7y9WCXtGP-FK9B9aoF35hHQrsWzJRVafuDbyXm0IP0zNANT82fPIxceEffzldzzAQsCbTF1yrJJuD1RzU%7ERF8rG4pg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.164.174.68, 18.164.174.110, 18.164.174.21, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.164.174.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662513657 (632M) [application/octet-stream]\n",
            "Saving to: ‘pytorch_model.bin’\n",
            "\n",
            "pytorch_model.bin   100%[===================>] 631.82M  72.6MB/s    in 6.7s    \n",
            "\n",
            "2025-12-26 05:19:40 (94.1 MB/s) - ‘pytorch_model.bin’ saved [662513657/662513657]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin"
      ],
      "id": "xf1Krw-icouI"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la pytorch_model.bin"
      ],
      "metadata": {
        "id": "n3rTXxpX1xh7",
        "outputId": "cfd4b6b2-8e59-442c-ff0f-b0309b1d4d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n3rTXxpX1xh7",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 662513657 Dec 26 05:19 pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s load the pre-trained weights."
      ],
      "metadata": {
        "id": "OeS0Tmfi2ldI"
      },
      "id": "OeS0Tmfi2ldI"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7Cl9w6wLcouI",
        "outputId": "c4f6b70c-7035-4820-de5b-e349d56d978d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "state_dict = torch.load('pytorch_model.bin')\n",
        "get_parm_dtypes(iter(state_dict.values()))"
      ],
      "id": "7Cl9w6wLcouI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "let’s make our choice of\n",
        "data type explicit using the dtype argument at all times."
      ],
      "metadata": {
        "id": "Q83AOPlr2q6J"
      },
      "id": "Q83AOPlr2q6J"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j2-5pMsKcouJ"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             dtype=torch.float32)"
      ],
      "id": "j2-5pMsKcouJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s send a dummy input to our model so it can calculate the corresponding loss:"
      ],
      "metadata": {
        "id": "8tkuk9SF2tlt"
      },
      "id": "8tkuk9SF2tlt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61pQD5v8couJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "batch = tokenizer(['This is a simple test'], return_tensors='pt')\n",
        "batch['labels'] = batch['input_ids']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch = {k: v.to(device) for k, v in batch.items()}"
      ],
      "id": "61pQD5v8couJ"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "INur0ylwcouJ",
        "outputId": "d2098bc3-3a76-4375-bf00-dcafc0c601d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8001, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "INur0ylwcouJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVbXXhAIcouJ"
      },
      "source": [
        "#### Half-Precision Models (16-bit)"
      ],
      "id": "KVbXXhAIcouJ"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "39itnhEGcouK",
        "outputId": "340ee866-2bd1-4c21-b2ce-8060b0c6fb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "dtype16 = (torch.bfloat16 if supported else torch.float16)\n",
        "dtype16"
      ],
      "id": "39itnhEGcouK"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "csD9SSHjcouK",
        "outputId": "e43b38a7-3dfa-48cf-b542-c7a796a299d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.to(dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "get_parm_dtypes(model.parameters())"
      ],
      "id": "csD9SSHjcouK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can load halfprecision\n",
        "weights directly by specifying the dtype argument when calling the from_pretrained()\n",
        "method."
      ],
      "metadata": {
        "id": "pAlgICQn37h0"
      },
      "id": "pAlgICQn37h0"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Xzol561UcouK",
        "outputId": "5cd0f8b6-d6bb-491b-b94b-8de1079b568f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n",
            "[(torch.float16, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             dtype=dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "Xzol561UcouK"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Uf-Fzf-bcouK",
        "outputId": "1ede1188-629e-42f9-d934-ca872a5c0169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8012, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "Uf-Fzf-bcouK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG4z0k2acouK"
      },
      "source": [
        "### Mixed Precision"
      ],
      "id": "cG4z0k2acouK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep in mind that the goal of using mixed precision is not to reduce the model’s memory footprint but to\n",
        "speed up the forward pass."
      ],
      "metadata": {
        "id": "QemcdxodZOXN"
      },
      "id": "QemcdxodZOXN"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KkbfFYjDcouL"
      },
      "outputs": [],
      "source": [
        "class MixedModel(nn.Module):\n",
        "    def __init__(self, dtype):\n",
        "        super().__init__()\n",
        "        self.a = nn.Linear(1000, 1000, dtype=dtype)\n",
        "        self.b = nn.Linear(1000, 1000, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.b(self.a(x))"
      ],
      "id": "KkbfFYjDcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8gFPkr_1couL",
        "outputId": "2b6bcb44-6cf1-43a9-c642-55897980b6af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "mixed32 = MixedModel(torch.float32)\n",
        "mixed32.to('cuda')"
      ],
      "id": "8gFPkr_1couL"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mVguUsezcouL",
        "outputId": "175859bc-5714-4eb6-847c-673b5be65d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.32 ms ± 12.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "mVguUsezcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9EG2KRQbcouL",
        "outputId": "b71fa031-3c0f-4f66-865e-b76902e5fb7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "mixed16 = MixedModel(torch.float16)\n",
        "mixed16.to('cuda')"
      ],
      "id": "9EG2KRQbcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GTgUF0rHcouL",
        "outputId": "75b8356a-4047-4e64-f4ce-900efc4de47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234 µs ± 2.07 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed16(torch.randn(1000, 1000, dtype=torch.float16, device='cuda'))"
      ],
      "id": "GTgUF0rHcouL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "we’ll be using PyTorch’s\n",
        "context manager, which allows regions of\n",
        "a script to run in mixed precision with the desired data type."
      ],
      "metadata": {
        "id": "XfTt_yfCZW3w"
      },
      "id": "XfTt_yfCZW3w"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "FmaQ1y4GcouM",
        "outputId": "4990b134-7ce5-4c75-a6c1-365fe760a024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257 µs ± 541 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    %timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "FmaQ1y4GcouM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any output produced inside the context manager will necessarily\n",
        "have the context manager’s data type. Therefore, we’d have to cast these outputs back to FP32."
      ],
      "metadata": {
        "id": "_pNs0cWWZofs"
      },
      "id": "_pNs0cWWZofs"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Jj0mqmPtcouM"
      },
      "outputs": [],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    res16 = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "\n",
        "res32 = res16.float()"
      ],
      "id": "Jj0mqmPtcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7TdVkcD5couM"
      },
      "outputs": [],
      "source": [
        "autocast_context = torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
        "# original forward method\n",
        "model_forward_func = mixed32.forward.__func__\n",
        "# wrapping the method with the context manager\n",
        "new_forward = autocast_context(model_forward_func)\n",
        "# assigning the wrapped method back to the model\n",
        "mixed32.forward = MethodType(new_forward, mixed32)"
      ],
      "id": "7TdVkcD5couM"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fgSwTg9JcouM",
        "outputId": "5ac9ab93-d641-4d26-8882-cc9e535b64b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "fgSwTg9JcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yRLrCoC2couM"
      },
      "outputs": [],
      "source": [
        "mixed32.forward = MethodType(convert_outputs_to_fp32(mixed32.forward.__func__), mixed32)"
      ],
      "id": "yRLrCoC2couM"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mn1tKOLUcouM",
        "outputId": "3cd38c4a-ffb3-4081-a2c4-3bcca38e2e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "mn1tKOLUcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_jdVpWXecouM",
        "outputId": "cb2800b7-1e2d-48ba-b3df-a4593178c9c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "_jdVpWXecouM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxxgn5nmcouN"
      },
      "source": [
        "### BitsAndBytes\n",
        "\n",
        "[BitsAndBytes](https://huggingface.co/docs/bitsandbytes/main/en/index) is your go-to package for quantization. From its documentation:\n",
        "\n",
        "\"_bitsandbytes enables accessible large language models via k-bit quantization for PyTorch. bitsandbytes provides three main features for dramatically reducing memory consumption for inference and training:_\n",
        "\n",
        "- _8-bit optimizers uses block-wise quantization to maintain 32-bit performance at a small fraction of the memory cost._\n",
        "- _LLM.Int() or 8-bit quantization enables large language model inference with only half the required memory and without any performance degradation. This method is based on vector-wise quantization to quantize most features to 8-bits and separately treating outliers with 16-bit matrix multiplication._\n",
        "- _QLoRA or 4-bit quantization enables large language model training with several memory-saving techniques that don’t compromise performance. This method quantizes a model to 4-bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training._\""
      ],
      "id": "Dxxgn5nmcouN"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "scrolled": true,
        "id": "X8AM7sgecouN",
        "outputId": "537e8aa0-50af-46ba-da6e-8ae744ccfd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BitsAndBytesConfig {\n",
              "  \"_load_in_4bit\": false,\n",
              "  \"_load_in_8bit\": false,\n",
              "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "  \"bnb_4bit_quant_type\": \"fp4\",\n",
              "  \"bnb_4bit_use_double_quant\": false,\n",
              "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "  \"llm_int8_has_fp16_weight\": false,\n",
              "  \"llm_int8_skip_modules\": null,\n",
              "  \"llm_int8_threshold\": 6.0,\n",
              "  \"load_in_4bit\": false,\n",
              "  \"load_in_8bit\": false,\n",
              "  \"quant_method\": \"bitsandbytes\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig()\n",
        "bnb_config"
      ],
      "id": "X8AM7sgecouN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udyEUr2IcouN"
      },
      "source": [
        "#### 8-Bit Quantization\n",
        "\n",
        "\"_LLM.int8() is a quantization method that doesn’t degrade performance which makes large model inference more accessible. The key is to extract the outliers from the inputs and weights and multiply them in 16-bit. All other values are multiplied in 8-bit and quantized to Int8 before being dequantized back to 16-bits. The outputs from the 16-bit and 8-bit multiplication are combined to produce the final output._\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)\n",
        "\n",
        "****\n",
        "**Summary of \"8-Bit Quantization\"**\n",
        "- load an 8-bit quantized model in a few lines of code:\n",
        "  ```python\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                                 device_map='cuda:0',\n",
        "                                                 torch_dtype=torch.float32,\n",
        "                                                 quantization_config=bnb_config)\n",
        "  ```\n",
        "  - quantization modifies the default type of non-quantized layers to `torch.float16` unless we actively provide the `torch_dtype` argument when calling the `from_pretrained()` method\n",
        "- 8-bit quantization replaces all linear layers except for:\n",
        "  - layers with tied (shared) weights\n",
        "  - the last layer in the model\n",
        "  - any layer named `lm_head`\n",
        "- if you want to skip additional modules, use the `llm_int8_skip_modules` configuration argument and make sure to manually include the layers with tied (shared) weights to avoid errors\n",
        "- computation (inside the quantized layers) happens in `torch.float16`\n",
        "****"
      ],
      "id": "udyEUr2IcouN"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cgNj4HDVcouN"
      },
      "outputs": [],
      "source": [
        "bnb_config_q8 = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_q8 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8)"
      ],
      "id": "cgNj4HDVcouN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_q8.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8.parameters()))"
      ],
      "metadata": {
        "id": "SWJQ6nCklZTl",
        "outputId": "6875bb40-1d44-4108-d521-9d909eb755b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SWJQ6nCklZTl",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359.354368\n",
            "[(torch.float16, 242), (torch.int8, 146)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "F7J4uVb_couN",
        "outputId": "5c5e1088-ee7f-42d9-8f3c-1a72770dc054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8339, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# you may not get a NaN back, as it depends on the environment\n",
        "out = model_q8(**batch)\n",
        "out.loss"
      ],
      "id": "F7J4uVb_couN"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0d_kWK0UcouN",
        "outputId": "5b5edaad-4cf6-48bb-b11f-eed9b1d4d479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        }
      ],
      "source": [
        "model_q8_32 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8,\n",
        "                                                torch_dtype=torch.float32)"
      ],
      "id": "0d_kWK0UcouN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_q8_32.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8_32.parameters()))"
      ],
      "metadata": {
        "id": "uCN-3veEm4RX",
        "outputId": "cae7d738-e335-41b0-e9a0-c7543d3519f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uCN-3veEm4RX",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "415.670272\n",
            "[(torch.float32, 242), (torch.int8, 146)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Bp3pKOVpcouO",
        "outputId": "f3663dce-8b2c-40eb-eb24-4e1140df44b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py:123: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8012, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "out = model_q8_32(**batch)\n",
        "out.loss"
      ],
      "id": "Bp3pKOVpcouO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyMitVE0couO"
      },
      "source": [
        "##### Quantized Linear Layers"
      ],
      "id": "wyMitVE0couO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s take a closer look at one of the attention blocks that had its linear layers quantized."
      ],
      "metadata": {
        "id": "PZDqTPWR7PcY"
      },
      "id": "PZDqTPWR7PcY"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "z_Plxf8KcouO",
        "outputId": "5f483b2c-ac39-421a-a432-267135124a72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "dec_layer = model_q8_32.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "z_Plxf8KcouO"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "eBlH1YMscouO",
        "outputId": "ec33c59e-9247-49d8-f281-983025edb902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear8bitLt(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "q8_layer = dec_layer.self_attn.k_proj\n",
        "q8_layer"
      ],
      "id": "eBlH1YMscouO"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "za13SRWccouO",
        "outputId": "82a74d49-9d3a-4181-d2a9-69dbefa242ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -67, -113,  -89,  ...,   65,  -16,  -87],\n",
              "                      [  60,  120,   90,  ...,  -50,   32,   80],\n",
              "                      [  47,  127,   86,  ...,  -34,    8,   90],\n",
              "                      ...,\n",
              "                      [ -65,   65,   34,  ...,  -64,   35,   64],\n",
              "                      [  57,   67,   21,  ...,   63,  -64,  -64],\n",
              "                      [ -64,   63,  -11,  ...,  -64,   34,   63]], device='cuda:0',\n",
              "                     dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.1250, 0.1252, 0.1250,  ..., 0.1252, 0.1250, 0.1254], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "q8_state = q8_layer.state_dict()\n",
        "q8_state"
      ],
      "id": "za13SRWccouO"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "yCIOaNiTcouO",
        "outputId": "ac964514-73e9-4a58-d9f8-5c2c0a90f857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(50272, 512, padding_idx=1)\n",
            "Linear(in_features=512, out_features=50272, bias=False)\n"
          ]
        }
      ],
      "source": [
        "print(model.model.decoder.embed_tokens)\n",
        "print(model.lm_head)"
      ],
      "id": "yCIOaNiTcouO"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "TdBC5TghcouQ",
        "outputId": "f976e215-7a23-4f00-c35b-0988f6f93353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "torch.allclose(model.model.decoder.embed_tokens.weight,\n",
        "               model.lm_head.weight)"
      ],
      "id": "TdBC5TghcouQ"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "36qswA_fcouQ",
        "outputId": "e6c84132-aa77-4330-e96b-9460125b8d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, [['lm_head.weight', 'model.decoder.embed_tokens.weight']])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
        "\n",
        "config.tie_word_embeddings, find_tied_parameters(model)"
      ],
      "id": "36qswA_fcouQ"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "w3NT1VkccouQ",
        "outputId": "a8c0bacb-1d89-4e5f-899e-3459a970335a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(..., device='meta', size=(50272, 512), dtype=torch.float16,\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "with init_empty_weights(): # loads meta tensors only\n",
        "    empty_model = AutoModelForCausalLM.from_config(config)\n",
        "\n",
        "empty_model.lm_head.weight"
      ],
      "id": "w3NT1VkccouQ"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "uFC604zscouQ",
        "outputId": "404e5119-a027-4eb0-bde2-58daca3e4ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lm_head', 'model.decoder.embed_tokens']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "skip_modules = get_keys_to_not_convert(empty_model)\n",
        "skip_modules"
      ],
      "id": "uFC604zscouQ"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "TZazkdwdcouQ",
        "outputId": "8b6c6188-d608-4be0-f4a5-0134511e407a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lm_head: torch.float32\n",
            "model.decoder.embed_tokens: torch.float32\n"
          ]
        }
      ],
      "source": [
        "for module in skip_modules:\n",
        "    print(f'{module}: {next(model_q8_32.get_submodule(module).parameters()).dtype}')"
      ],
      "id": "TZazkdwdcouQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfzKRMGicouR"
      },
      "source": [
        "#### `llm_int8_skip_modules`\n",
        "\n",
        "If your model has tied weights, and you choose to use your own list of modules to skip, you\n",
        "must add one of the tied layers to your list. If you don’t, you may get the following\n",
        "exception:\n",
        "\n",
        "***\n",
        "`AttributeError: 'Parameter' object has no attribute 'SCB'`\n",
        "***\n",
        "\n",
        "```python\n",
        "# This configuration WILL raise an exception\n",
        "# while trying to load weights for the tied layer\n",
        "# bnb_config_skip = BitsAndBytesConfig(load_in_8bit=True,\n",
        "#                                      llm_int8_skip_modules=['o_proj'])\n",
        "\n",
        "# This configuration works fine because\n",
        "# the tied layer, lm_head, is in the list\n",
        "bnb_config_skip = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        llm_int8_skip_modules=['o_proj', 'lm_head'])\n",
        "\n",
        "model_skip = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                  device_map='cuda:0',\n",
        "                                                  torch_dtype=torch.float32,\n",
        "                                                  quantization_config=bnb_config_skip)\n",
        "```"
      ],
      "id": "UfzKRMGicouR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Xm9K9tcouR"
      },
      "source": [
        "##### 8-bit Layers\n",
        "\n",
        "The quantization of each layer occurs when they’re sent to the GPU.\n",
        "\n",
        "\"*In order to quantize a linear layer one should first load the original fp16 / bf16 weights into the Linear8bitLt module, then call int8_module.to(\"cuda\") to quantize the fp16 weights.*\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)"
      ],
      "id": "d8Xm9K9tcouR"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Egv4taFkcouR",
        "outputId": "6adcab9d-4e78-493a-91e0-202d857c931b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.2220, -0.0085,  0.3072, -0.2097,  0.0531,  0.1224,  0.0525, -0.2350,\n",
              "                        0.0456,  0.2687],\n",
              "                      [-0.1459,  0.1786, -0.1443, -0.0233,  0.1689,  0.0015, -0.2514,  0.1644,\n",
              "                        0.1920,  0.1678],\n",
              "                      [ 0.2346,  0.1411,  0.2128,  0.0519,  0.2147, -0.2786, -0.0433, -0.0364,\n",
              "                       -0.1504,  0.0823],\n",
              "                      [ 0.2388, -0.2134, -0.1620, -0.1023,  0.2433, -0.2680,  0.3099, -0.1933,\n",
              "                       -0.0471, -0.0391],\n",
              "                      [-0.1273,  0.2197, -0.0136, -0.1938, -0.1746,  0.0404,  0.0711, -0.1730,\n",
              "                        0.0539, -0.1992],\n",
              "                      [-0.0051,  0.1373, -0.0267, -0.0907, -0.0107,  0.1108, -0.1566,  0.0172,\n",
              "                        0.2075, -0.0028],\n",
              "                      [ 0.2082, -0.2857, -0.2640, -0.1436,  0.1704,  0.1908, -0.2350,  0.1187,\n",
              "                       -0.0568,  0.0916],\n",
              "                      [ 0.2974, -0.3061,  0.0559,  0.1899,  0.0265, -0.1893, -0.0582, -0.0943,\n",
              "                        0.2451,  0.2825],\n",
              "                      [-0.1241, -0.3106, -0.1002, -0.1745,  0.2693,  0.2985,  0.1633, -0.0270,\n",
              "                       -0.3049,  0.0227],\n",
              "                      [-0.1217,  0.0035, -0.1481, -0.0330,  0.1787,  0.3123,  0.2600, -0.1720,\n",
              "                        0.2059,  0.2057]])),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854]))])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "\n",
        "torch.manual_seed(11)\n",
        "fp_layer = nn.Linear(n_in, n_out)\n",
        "\n",
        "int8_layer = Linear8bitLt(n_in, n_out, has_fp16_weights=False)\n",
        "\n",
        "int8_layer.load_state_dict(fp_layer.state_dict())\n",
        "int8_layer.state_dict()"
      ],
      "id": "Egv4taFkcouR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, nothing was quantized yet.\n",
        "\n",
        "Let’s send it to the GPU now."
      ],
      "metadata": {
        "id": "fYYwzq4i_LIR"
      },
      "id": "fYYwzq4i_LIR"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "hc8iwYmacouR",
        "outputId": "9e95bcc7-ac7d-4862-bc0f-c1bde285ace1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -92,   -4,  127,  -87,   22,   51,   22,  -97,   19,  111],\n",
              "                      [ -74,   90,  -73,  -12,   85,    1, -127,   83,   97,   85],\n",
              "                      [ 107,   64,   97,   24,   98, -127,  -20,  -17,  -69,   38],\n",
              "                      [  98,  -87,  -66,  -42,  100, -110,  127,  -79,  -19,  -16],\n",
              "                      [ -74,  127,   -8, -112, -101,   23,   41, -100,   31, -115],\n",
              "                      [  -3,   84,  -16,  -56,   -7,   68,  -96,   11,  127,   -2],\n",
              "                      [  93, -127, -117,  -64,   76,   85, -104,   53,  -25,   41],\n",
              "                      [ 123, -127,   23,   79,   11,  -79,  -24,  -39,  102,  117],\n",
              "                      [ -51, -127,  -41,  -71,  110,  122,   67,  -11, -125,    9],\n",
              "                      [ -50,    1,  -60,  -13,   73,  127,  106,  -70,   84,   84]],\n",
              "                     device='cuda:0', dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854], device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.3071, 0.2515, 0.2786, 0.3098, 0.2197, 0.2075, 0.2856, 0.3062, 0.3105,\n",
              "                      0.3123], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "int8_layer = int8_layer.to(0) # Quantization happens here\n",
        "int8_state = int8_layer.state_dict()\n",
        "int8_state"
      ],
      "id": "hc8iwYmacouR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Rn3bzEcouS"
      },
      "source": [
        "#### 4-bit Quantization\n",
        "\n",
        "\"*QLoRA is a finetuning method that quantizes a model to 4-bits and adds a set of low-rank adaptation (LoRA) weights to the model and tuning them through the quantized weights. This method also introduces a new data type, 4-bit NormalFloat (LinearNF4) in addition to the standard Float4 data type (LinearFP4). LinearNF4 is a quantization data type for normally distributed data and can improve performance.*\"\n",
        "\n",
        "Source: [4-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear4bit)\n",
        "\n",
        "****\n",
        "**Summary of \"4-Bit Quantization\"**\n",
        "- squeeze the most of a 4-bit quantized model by using the normal float (NF4) type and double quantization\n",
        "  ```python\n",
        "  supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "  compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "  nf4_config = BitsAndBytesConfig(\n",
        "     load_in_4bit=True,\n",
        "     bnb_4bit_quant_type=\"nf4\",\n",
        "     bnb_4bit_use_double_quant=True,\n",
        "     bnb_4bit_compute_dtype=compute_dtype\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                               device_map='cuda:0',\n",
        "                                               torch_dtype=torch.float32,\n",
        "                                               quantization_config=nf4_config)\n",
        "  ```\n",
        "- computation happens (inside the quantized layers) in the specified type (`bnb_4bit_compute_dtype`):\n",
        "FP32 is better than BF16, which is better than FP16.\n",
        "****"
      ],
      "id": "G4Rn3bzEcouS"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "oeL_JkppcouS"
      },
      "outputs": [],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=compute_dtype\n",
        ")"
      ],
      "id": "oeL_JkppcouS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDHXTuk8couS"
      },
      "source": [
        "**The Secret Lives of `Dtypes`**\n",
        "\n",
        "| Regular Model | Quantized Model |\n",
        "|---|---|\n",
        "| ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_regular.png?raw=True) | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_qt.png?raw=True) |\n",
        "| <center>Figure 2.6 - Data types flowing through a regular model</center> | <center>Figure 2.7 - Data types flowing through a quantized model</center> |"
      ],
      "id": "NDHXTuk8couS"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pDxQDfN2couS",
        "outputId": "1f65dc58-d6b1-4079-a453-7c25055accfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "264.15104\n",
            "[(torch.float32, 242), (torch.uint8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q4 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                torch_dtype=torch.float32,\n",
        "                                                quantization_config=nf4_config)\n",
        "print(model_q4.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q4.parameters()))"
      ],
      "id": "pDxQDfN2couS"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "kHCCXE4AcouT",
        "outputId": "b53e5b8f-6baf-481b-8e99-5789729c4978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7016, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "out = model_q4(**batch)\n",
        "out.loss"
      ],
      "id": "kHCCXE4AcouT"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "CUU3jtoHcouT",
        "outputId": "752b979b-1a4b-4277-c53b-7d9c5c314666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "dec_layer = model_q4.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "CUU3jtoHcouT"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mg3ISjIZcouT",
        "outputId": "195194ef-12ab-4096-b007-2527a41f0431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear4bit(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "q4_layer = dec_layer.self_attn.k_proj\n",
        "q4_layer"
      ],
      "id": "mg3ISjIZcouT"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ukhL6HCacouU",
        "outputId": "7d983227-50f5-44c4-f6c0-cd868899997f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 32],\n",
              "                      [ 29],\n",
              "                      [208],\n",
              "                      ...,\n",
              "                      [ 66],\n",
              "                      [ 34],\n",
              "                      [172]], device='cuda:0', dtype=torch.uint8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0')),\n",
              "             ('weight.absmax',\n",
              "              tensor([230, 230,  30,  ...,   1,  26, 191], device='cuda:0',\n",
              "                     dtype=torch.uint8)),\n",
              "             ('weight.quant_map',\n",
              "              tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "                       0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "                     device='cuda:0')),\n",
              "             ('weight.nested_absmax',\n",
              "              tensor([0.0077, 0.0142, 0.0153, 0.0138, 0.0399, 0.0409, 0.0417, 0.0426, 0.0053,\n",
              "                      0.0053, 0.0053, 0.0053, 0.0051, 0.0051, 0.0051, 0.0053, 0.0195, 0.0269,\n",
              "                      0.0223, 0.0195, 0.0053, 0.0053, 0.0054, 0.0054, 0.0317, 0.0315, 0.0306,\n",
              "                      0.0320, 0.0262, 0.0265, 0.0230, 0.0296, 0.0051, 0.0065, 0.0050, 0.0050,\n",
              "                      0.0051, 0.0053, 0.0050, 0.0051, 0.0056, 0.0056, 0.0056, 0.0056, 0.0428,\n",
              "                      0.0410, 0.0405, 0.0422, 0.0397, 0.0402, 0.0394, 0.0414, 0.0204, 0.0106,\n",
              "                      0.0140, 0.0078, 0.0406, 0.0349, 0.0359, 0.0418, 0.0503, 0.0499, 0.0470,\n",
              "                      0.0458], device='cuda:0')),\n",
              "             ('weight.nested_quant_map',\n",
              "              tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
              "                      -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
              "                      -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
              "                      -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
              "                      -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
              "                      -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
              "                      -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
              "                      -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
              "                      -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
              "                      -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
              "                      -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
              "                      -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
              "                      -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
              "                      -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
              "                      -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
              "                      -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
              "                      -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
              "                      -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
              "                      -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
              "                      -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
              "                      -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
              "                      -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
              "                      -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
              "                      -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
              "                      -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
              "                      -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
              "                       7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
              "                       1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
              "                       7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
              "                       2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
              "                       5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
              "                       8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
              "                       1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
              "                       2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
              "                       4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
              "                       5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
              "                       7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
              "                       8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
              "                       9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
              "                       1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
              "                       2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
              "                       3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
              "                       3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
              "                       4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
              "                       5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
              "                       5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
              "                       6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
              "                       7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
              "                       7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
              "                       8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
              "                       9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
              "                       1.0000e+00], device='cuda:0')),\n",
              "             ('weight.quant_state.bitsandbytes__nf4',\n",
              "              tensor([123,  34, 113, 117,  97, 110, 116,  95, 116, 121, 112, 101,  34,  58,\n",
              "                       32,  34, 110, 102,  52,  34,  44,  32,  34,  98, 108, 111,  99, 107,\n",
              "                      115, 105, 122, 101,  34,  58,  32,  54,  52,  44,  32,  34, 100, 116,\n",
              "                      121, 112, 101,  34,  58,  32,  34, 102, 108, 111,  97, 116,  51,  50,\n",
              "                       34,  44,  32,  34, 115, 104,  97, 112, 101,  34,  58,  32,  91,  49,\n",
              "                       48,  50,  52,  44,  32,  49,  48,  50,  52,  93,  44,  32,  34, 110,\n",
              "                      101, 115, 116, 101, 100,  95,  98, 108, 111,  99, 107, 115, 105, 122,\n",
              "                      101,  34,  58,  32,  50,  53,  54,  44,  32,  34, 110, 101, 115, 116,\n",
              "                      101, 100,  95, 100, 116, 121, 112, 101,  34,  58,  32,  34, 102, 108,\n",
              "                      111,  97, 116,  51,  50,  34,  44,  32,  34, 110, 101, 115, 116, 101,\n",
              "                      100,  95, 111, 102, 102, 115, 101, 116,  34,  58,  32,  48,  46,  49,\n",
              "                       49,  57,  57,  56,  49,  55,  50,  49,  48,  52,  51,  53,  56,  54,\n",
              "                       55,  51, 125], dtype=torch.uint8))])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "q4_layer.state_dict()"
      ],
      "id": "ukhL6HCacouU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14FQv-kcouU"
      },
      "source": [
        "##### FP4 vs NF4 Layers"
      ],
      "id": "l14FQv-kcouU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let’s create a regular linear layer:"
      ],
      "metadata": {
        "id": "jaCBVy9sJxer"
      },
      "id": "jaCBVy9sJxer"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "YhnFSUHLcouU",
        "outputId": "3a0fe218-5a3c-4581-9000-9565486e61c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "torch.manual_seed(11)\n",
        "fp16_layer = nn.Linear(n_in, n_out)\n",
        "fp16_layer"
      ],
      "id": "YhnFSUHLcouU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let’s load its state dictionary into both FP4 and NF4 layers:"
      ],
      "metadata": {
        "id": "edXD7z8zJ3qh"
      },
      "id": "edXD7z8zJ3qh"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "WhFRo-XNcouU",
        "outputId": "746eb9a7-2987-43be-e0a3-68c321be15ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "fp4_layer = LinearFP4(n_in, n_out)\n",
        "fp4_layer.load_state_dict(fp16_layer.state_dict())\n",
        "\n",
        "nf4_model = LinearNF4(n_in, n_out)\n",
        "nf4_model.load_state_dict(fp16_layer.state_dict())"
      ],
      "id": "WhFRo-XNcouU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s\n",
        "try the FP4 layer first:"
      ],
      "metadata": {
        "id": "Vsep-l_xKBQJ"
      },
      "id": "Vsep-l_xKBQJ"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "QiiUHsSNcouU",
        "outputId": "49bfd340-0f64-441a-ecb2-84409007da75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
              "          0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "fp4_layer = fp4_layer.to(0) # Quantization happens here\n",
        "fp4_state = fp4_layer.state_dict()\n",
        "\n",
        "fp4_state['weight.quant_map'], fp4_state['weight'].shape"
      ],
      "id": "QiiUHsSNcouU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The locations of the bins are plotted below to help us visualize their distribution."
      ],
      "metadata": {
        "id": "9Cnp-U1dKMYI"
      },
      "id": "9Cnp-U1dKMYI"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "-7g3b9ShcouU",
        "outputId": "2b0bbc32-2cd8-4b70-a002-5393fc1cacc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'FP4 quantization')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(fp4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('FP4 quantization')"
      ],
      "id": "-7g3b9ShcouU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about the NF4 layer? Let’s force its quantization, too."
      ],
      "metadata": {
        "id": "wDBKzlGUKSfa"
      },
      "id": "wDBKzlGUKSfa"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "JP0avxs6couU",
        "outputId": "5480913d-5783-4adc-af5a-10e1ef3919e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "nf4_model = nf4_model.to(0) # Quantization happens here\n",
        "nf4_state = nf4_model.state_dict()\n",
        "\n",
        "nf4_state['weight.quant_map'], nf4_state['weight'].shape"
      ],
      "id": "JP0avxs6couU"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "fqVn1Or4couU",
        "outputId": "475897d0-7736-4b9e-f181-80df0ec33075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'NF4 quantization')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(nf4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('NF4 quantization')"
      ],
      "id": "fqVn1Or4couU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPK-WKvMcouV"
      },
      "source": [
        "### Coming Up in \"Fine-Tuning LLMs\"\n",
        "\n",
        "As huge linear layers are being replaced by their quantized versions to reduce the model’s memory footprint, a\n",
        "new issue arises. These quantized layers cannot be easily updated, thus rendering fine-tuning next to\n",
        "impossible. Could a new kind of layer be the solution to this conundrum? Find out in the next thrilling chapter\n",
        "of \"Fine-Tuning LLMs.\""
      ],
      "id": "tPK-WKvMcouV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}