{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/small-language-models-fine-tuning/blob/main/hands-on-llm-fine-tuning-with-pytorch-and-huggingface/01_loading_quantized_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYLXKf47cotm"
      },
      "source": [
        "## Chapter 2: Loading a Quantized Model"
      ],
      "id": "NYLXKf47cotm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sbYPOA0cotp"
      },
      "source": [
        "### Spoilers\n",
        "\n",
        "In this chapter, we’ll:\n",
        "\n",
        "- Understand how quantization works\n",
        "- Explore the pros and cons of using different data types (FP16, BF16, FP32)\n",
        "- Introduce the concept of mixed-precision computing\n",
        "- Use BitsAndBytes to quantize a pretrained model while loading it"
      ],
      "id": "5sbYPOA0cotp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMAZGnxLcotp"
      },
      "source": [
        "### Setup"
      ],
      "id": "bMAZGnxLcotp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kODUm5BmEQhI"
      },
      "outputs": [],
      "source": [
        "# If you're running on Colab\n",
        "!pip install datasets bitsandbytes trl"
      ],
      "id": "kODUm5BmEQhI"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YH-5DqVPcotr"
      },
      "outputs": [],
      "source": [
        "# If you're running on runpod.io's Jupyter Template\n",
        "#!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib"
      ],
      "id": "YH-5DqVPcotr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF5_Qir0cotr"
      },
      "source": [
        "### Imports"
      ],
      "id": "LF5_Qir0cotr"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j2CPDad7cots"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from accelerate import init_empty_weights\n",
        "from accelerate.utils.modeling import find_tied_parameters, get_mixed_precision_context_manager\n",
        "from accelerate.utils.operations import convert_outputs_to_fp32\n",
        "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4, LinearNF4\n",
        "from collections import Counter\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
        "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
        "from types import MethodType\n",
        "from matplotlib import pyplot as plt"
      ],
      "id": "j2CPDad7cots"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxctCF0ucots"
      },
      "source": [
        "### The Goal\n",
        "\n",
        "We quantize models to reduce their memory footprint. We can easily shrink the model’s size to a quarter or an eighth of its original size. Keep in mind, however, that the more a model is quantized (i.e., the fewer bit used\n",
        "to represent its weights), the more likely its performance will be negatively affected."
      ],
      "id": "zxctCF0ucots"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ZPL7f_cott"
      },
      "source": [
        "### Pre-Reqs\n",
        "\n",
        "| Type | Name | # bits | Nickname |\n",
        "|---|---|---|---|\n",
        "| FP32 | Floating Point | 32 | Full Precision |\n",
        "| BF16 | Brain Float | 16 | Half-Precision |\n",
        "| FP16 | Floating Point | 16 | Half-Precision |\n",
        "| INT8 | Integer | 8 | 8-bit Quantized |\n",
        "| FP4 | Floating Point | 4 | 4-bit Quantized |\n",
        "| NF4 | Normal Float | 4 | 4-bit Quantized |\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_sizes.png?raw=True)\n",
        "<center>Figure 2.1 - Data type’s size comparison</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/model_sizes.png?raw=True)\n",
        "<center>Figure 2.2 - Representing the same model using different data types</center>"
      ],
      "id": "d4ZPL7f_cott"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP1DVuR8cotu"
      },
      "source": [
        "### Quantization in a Nutshell"
      ],
      "id": "xP1DVuR8cotu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole idea is actually quite simple, and it’s pretty much the same as building a histogram.\n",
        "\n",
        "Let’s go over a practical example. Say that you have 1,000 weights in the -0.2 to 0.2 range"
      ],
      "metadata": {
        "id": "0Suqb1gOeLTK"
      },
      "id": "0Suqb1gOeLTK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk8HVOutcotu",
        "outputId": "63e5969f-ae52-48b6-9b2d-828bf3e54b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.2066), tensor(0.2097))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "weights = torch.randn(1000) * .07\n",
        "weights.min(), weights.max()"
      ],
      "id": "bk8HVOutcotu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say you choose to use four bins only."
      ],
      "metadata": {
        "id": "YxfcwI50fCeZ"
      },
      "id": "YxfcwI50fCeZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlVUKyB6cotv",
        "outputId": "124a9ce7-1ed0-4133-c9a2-1b4c725495dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]), tensor(0.1041))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "n_bins = 4\n",
        "bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "bin_width = bins[1]-bins[0]\n",
        "bins, bin_width"
      ],
      "id": "KlVUKyB6cotv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrDixnBYcotw",
        "outputId": "28c6a346-fdaa-48d7-a70f-01d7da519ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(weights, bins=bins)\n",
        "ax.set_xlabel('Values')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "nrDixnBYcotw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compute the bin indexes for each weight."
      ],
      "metadata": {
        "id": "eKzQwAO_fjMU"
      },
      "id": "eKzQwAO_fjMU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db6spEdRcotw",
        "outputId": "4be83f22-926f-47a7-90cf-74a58833f853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n",
            "tensor([1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "print(weights[:20])\n",
        "print(bin_indexes[:20])"
      ],
      "id": "Db6spEdRcotw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_ZmN2yZcotw",
        "outputId": "7ad54633-0521-4d6b-b684-5a3bcb5a102b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(bin_indexes, bins=np.arange(n_bins+1)-.5)\n",
        "ax.set_xticks([0, 1, 2, 3])\n",
        "ax.set_xlabel('Bin Indexes')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "H_ZmN2yZcotw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef90ki3Rcotw"
      },
      "source": [
        "The number of bins you choose and the number of bits required to represent it are related to each other\n",
        "through the following expression:\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{n_bins}=2^{\\text{n_bits}} \\implies \\text{n_bits} = \\log_2({\\text{n_bins}})\n",
        "$$\n",
        "\n",
        "<center>Equation 2.1 - Number of bits vs number of bins</center>"
      ],
      "id": "Ef90ki3Rcotw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NASieePAcotw",
        "outputId": "4edda9c7-499b-44f3-aa35-b822f1438f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "bin_values = bins[:-1]\n",
        "first_bin = bin_values[0]\n",
        "bin_values"
      ],
      "id": "NASieePAcotw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqSN68KDcotx"
      },
      "source": [
        "To retrieve the (approximate) original values, we\n",
        "don’t even need to use it as a lookup table; we can simply use the following expression:\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{approx_value} = \\text{bin_index} * \\text{bin_width} + \\text{first_bin}\n",
        "$$\n",
        "\n",
        "<center>Equation 2.2 - Retrieving the (approximate) original value</center>"
      ],
      "id": "yqSN68KDcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s apply the expression above to the full range of bin indexes to double-check it works properly:"
      ],
      "metadata": {
        "id": "aY1SsDBMhEsv"
      },
      "id": "aY1SsDBMhEsv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezU4I6Gucotx",
        "outputId": "1e3fde0a-bdd5-4eb3-cf00-aac23a110c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.arange(0, n_bins) * bin_width + first_bin"
      ],
      "id": "ezU4I6Gucotx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKbEMdkOcotx",
        "outputId": "c52cfa5e-90ce-4892-f21c-56d8da6255bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066,  0.0015, -0.1026,\n",
            "        -0.1026, -0.1026,  0.1056, -0.1026,  0.0015,  0.0015, -0.1026, -0.1026,\n",
            "         0.0015,  0.1056, -0.2066, -0.2066])\n"
          ]
        }
      ],
      "source": [
        "approx_values = bin_indexes * bin_width + first_bin\n",
        "print(approx_values[:20])"
      ],
      "id": "OKbEMdkOcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, compare the approximate values to the original values:"
      ],
      "metadata": {
        "id": "YP8qCZQJhKma"
      },
      "id": "YP8qCZQJhKma"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB-zlzPdcotx",
        "outputId": "c3885981-6680-4b38-cb35-113776e8b515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n"
          ]
        }
      ],
      "source": [
        "print(weights[:20])"
      ],
      "id": "xB-zlzPdcotx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s kind of a crude approximation, isn’t it?\n",
        "\n",
        "We can have a better idea of how bad it really is by computing the\n",
        "root mean squared error (RMSE) as if the quantized values were \"predictions\" and the original values were\n",
        "\"targets.\""
      ],
      "metadata": {
        "id": "6tJ98kKYhhHt"
      },
      "id": "6tJ98kKYhhHt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGkhVvurcotx",
        "outputId": "1a0e3fd0-00e3-4275-d899-eec1a102954f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0615)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "mse_fn = nn.MSELoss()\n",
        "mse_fn(approx_values, weights).sqrt()"
      ],
      "id": "yGkhVvurcotx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6LkEECHcoty"
      },
      "outputs": [],
      "source": [
        "def quantize(weights, n_bits=8):\n",
        "    assert n_bits <= 16, \"Using more bits may very slow execution and/or crashing.\"\n",
        "    n_bins = 2**n_bits\n",
        "    bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "    first_bin = bins[0]\n",
        "    bin_width = bins[1]-bins[0]\n",
        "    bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "    return bin_indexes, bin_width, first_bin\n",
        "\n",
        "def dequantize(bin_indexes, bin_width, first_bin):\n",
        "    approx_values = bin_indexes * bin_width + first_bin\n",
        "    return approx_values"
      ],
      "id": "E6LkEECHcoty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s try comparing the RMSE of several quantization choices:"
      ],
      "metadata": {
        "id": "QBZN4AithvjF"
      },
      "id": "QBZN4AithvjF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cazt5adQcoty",
        "outputId": "b089254d-2200-4f8e-a1c3-9522684f26ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-bit Quantization:\n",
            "Approximation value: tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.06153079494833946\n",
            "\n",
            "\n",
            "4-bit Quantization:\n",
            "Approximation value: tensor([-0.0505,  0.0535, -0.0505,  0.0015, -0.0245, -0.1286])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.01522719394415617\n",
            "\n",
            "\n",
            "8-bit Quantization:\n",
            "Approximation value: tensor([-0.0359,  0.0714, -0.0261,  0.0080, -0.0131, -0.1058])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.0009653186425566673\n",
            "\n",
            "\n",
            "16-bit Quantization:\n",
            "Approximation value: tensor([-0.0359,  0.0718, -0.0248,  0.0085, -0.0128, -0.1049])\n",
            "Original value: tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "MSE value: 0.00014281623589340597\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n_bits in [2, 4, 8, 16]:\n",
        "    res = quantize(weights, n_bits=n_bits)\n",
        "    approx_values = dequantize(*res)\n",
        "    print(f'{n_bits}-bit Quantization:')\n",
        "    print(f\"Approximation value: {approx_values[:6]}\")\n",
        "    print(f\"Original value: {weights[:6]}\")\n",
        "    print(f\"MSE value: {mse_fn(approx_values, weights).sqrt()}\")\n",
        "    print('\\n')"
      ],
      "id": "cazt5adQcoty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the numbers above, 16-bit quantization looks pretty good, right?\n",
        "\n",
        "Using 16 bits for quantization means\n",
        "having 65,536 bins. That’s a lot of bins! However, there’s a better way to use 16 bits: we can simply cast our\n",
        "weights down to 16-bit floating-point (FP16) numbers, often referred to as half-precision."
      ],
      "metadata": {
        "id": "U3HwnG_7jOXz"
      },
      "id": "U3HwnG_7jOXz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQJlD4Gncoty"
      },
      "source": [
        "****\n",
        "**ASIDE: Weight Distribution of Phi-3's Linear Layers**\n",
        "\n",
        "The following plots show the weight distribution of a large linear layer, `qkv_proj`, within the self-\n",
        "attention block in Phi-3. Other layers, such as `o_proj`, also located within the self-attention block, and\n",
        "`gate_up_proj` and `down_proj`, in the MLP block, have very similar weight distributions. This layer is\n",
        "present in every one of the 32 decoder blocks (indicated by the number in square brackets). You’ll notice\n",
        "that these millions of weights are concentrated within a very narrow range. But there are a few outliers as\n",
        "well, so each subplot also contains the actual range of observed weights in the corresponding layer.\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/self_attn.qkv_proj.png?raw=True)\n",
        "<center>Figure 2.5 - Weight distribution of Phi-3 layers</center>\n",
        "\n",
        "****"
      ],
      "id": "WQJlD4Gncoty"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_oOMPsBcoty"
      },
      "source": [
        "### Half-Precision Weights"
      ],
      "id": "p_oOMPsBcoty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy6UvZ6Bcoty",
        "outputId": "347899ac-afc7-4934-f848-2656c59a5a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048],\n",
            "       dtype=torch.float16)\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n"
          ]
        }
      ],
      "source": [
        "fp16_weights = weights.to(torch.float16)\n",
        "print(fp16_weights[:6])\n",
        "print(weights[:6])"
      ],
      "id": "Oy6UvZ6Bcoty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aU8riUEcoty",
        "outputId": "5ee0c62d-c343-4ffe-ffcd-eab55b7cd051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.4244e-05)\n"
          ]
        }
      ],
      "source": [
        "print(mse_fn(fp16_weights, weights).sqrt())"
      ],
      "id": "1aU8riUEcoty"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d__tBPH2coty"
      },
      "source": [
        "#### Living on the Edge"
      ],
      "id": "d__tBPH2coty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imfkQHmFcoty",
        "outputId": "d7572f59-6023-428a-a2db-6e5d7537e312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.8526e-16)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(14)\n",
        "tiny_values = torch.randn(1000)*1e-5\n",
        "fp16_tiny_values = tiny_values.to(torch.float16)\n",
        "mse_fn(fp16_tiny_values, tiny_values)"
      ],
      "id": "imfkQHmFcoty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG6eoIgBcoty",
        "outputId": "c7218608-cce9-4837-a015-0136d726145d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.7241e-06,  1.1441e-05,  3.7199e-06, -1.1252e-06, -2.4735e-08])\n",
            "tensor([-2.7418e-06,  1.1444e-05,  3.6955e-06, -1.1325e-06, -0.0000e+00],\n",
            "       dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "print(tiny_values[155:160])\n",
        "print(fp16_tiny_values[155:160])"
      ],
      "id": "jG6eoIgBcoty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWKLVldNcoty",
        "outputId": "463d4086-1d64-4f68-9689-c63a66ddc9ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([155074.0938,  64881.6602,   2729.5815, -40790.6562,  68846.7188])\n",
            "tensor([    inf,  64896.,   2730., -40800.,     inf], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(19)\n",
        "large_values = torch.randn(1000)*1e5\n",
        "fp16_large_values = large_values.to(torch.float16)\n",
        "print(large_values[:5])\n",
        "print(fp16_large_values[:5])"
      ],
      "id": "IWKLVldNcoty"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvbihBFmcotz",
        "outputId": "584e1d5b-3b1b-4cba-9c50-3597bb37fca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp16_info = torch.finfo(torch.float16)\n",
        "fp16_info"
      ],
      "id": "JvbihBFmcotz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH6qElWPcotz",
        "outputId": "26906346-74c7-46ea-80ec-869e8d800f53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.960464477539063e-08"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smallest_subnormal = fp16_info.smallest_normal * 2**-10\n",
        "smallest_subnormal"
      ],
      "id": "iH6qElWPcotz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqqT8zpcot0"
      },
      "source": [
        "### The Brain Float"
      ],
      "id": "adqqT8zpcot0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCND_3pocot0",
        "outputId": "e454db6f-f2ca-463b-ae42-51cad8f46282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n",
            "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n"
          ]
        }
      ],
      "source": [
        "bf16_info = torch.finfo(torch.bfloat16)\n",
        "print(bf16_info)\n",
        "print(fp16_info)"
      ],
      "id": "sCND_3pocot0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvIMEreGcot0",
        "outputId": "a67623e2-b864-4977-b6ee-4ae2b1e515ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp32_info = torch.finfo(torch.float32)\n",
        "fp32_info"
      ],
      "id": "MvIMEreGcot0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skNlGbnKcot0",
        "outputId": "c4439823-780a-4e32-a434-0355063e0e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.555555582])\n",
            "tensor([0.555664062], dtype=torch.float16)\n",
            "tensor([0.554687500], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([0.555555555])\n",
        "torch.set_printoptions(precision=9)\n",
        "print(x)\n",
        "print(x.to(torch.float16))\n",
        "print(x.to(torch.bfloat16))\n",
        "torch.set_printoptions(precision=4)"
      ],
      "id": "skNlGbnKcot0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx0cNj4Rcot0"
      },
      "source": [
        "|Type | Precision | Sub-normal | Min. | Max. |\n",
        "|---|---|---|---|---|\n",
        "|FP32 | e-08 | e-45 | e-38 | e+38 |\n",
        "|BF16 | e-03  | NA | e-38 | e+38 |\n",
        "|FP16 | e-04  | e-08  | e-05 | e+04 |"
      ],
      "id": "tx0cNj4Rcot0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcvI696kcouF"
      },
      "source": [
        "### Loading Models\n",
        "\n",
        "****\n",
        "**Summary of \"Loading Models\"**\n",
        "- if supported by your GPU, use `torch.bfloat16` instead of `torch.float16` for all things 16-bit\n",
        " ```python\n",
        " supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        " dtypes16 = (torch.bfloat16 if supported else torch.float16)\n",
        " ```\n",
        "- when loading a pretrained model, always specify its `torch_dype` upfront\n",
        " ```python\n",
        " model = AutoModelForCausalLM.from_pretrained(repo_id, device_map='cuda:0', torch_dtype=torch.float32)\n",
        " ```\n",
        "****"
      ],
      "id": "AcvI696kcouF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI5TgC2bcouF"
      },
      "outputs": [],
      "source": [
        "def get_parm_dtypes(iterable, top_k=3):\n",
        "    return Counter([p.dtype for p in iterable]).most_common(top_k)"
      ],
      "id": "oI5TgC2bcouF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG0qr1fycouI",
        "outputId": "3a126e92-cbdc-4048-a551-ac540bae2603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324.785664\n",
            "[(torch.float32, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", device_map='cuda:0')\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "rG0qr1fycouI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s download the model’s .bin file containing the\n",
        "pretrained weights."
      ],
      "metadata": {
        "id": "SDPV3dyj2exv"
      },
      "id": "SDPV3dyj2exv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf1Krw-icouI"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin"
      ],
      "id": "xf1Krw-icouI"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la pytorch_model.bin"
      ],
      "metadata": {
        "id": "n3rTXxpX1xh7",
        "outputId": "723632d3-9424-4136-cf00-839cc4ed4621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n3rTXxpX1xh7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 662513657 Dec 18 05:02 pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s load the pre-trained weights."
      ],
      "metadata": {
        "id": "OeS0Tmfi2ldI"
      },
      "id": "OeS0Tmfi2ldI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cl9w6wLcouI",
        "outputId": "939794ee-e462-4f6f-827c-6d4862d3fc3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "state_dict = torch.load('pytorch_model.bin')\n",
        "get_parm_dtypes(iter(state_dict.values()))"
      ],
      "id": "7Cl9w6wLcouI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "let’s make our choice of\n",
        "data type explicit using the dtype argument at all times."
      ],
      "metadata": {
        "id": "Q83AOPlr2q6J"
      },
      "id": "Q83AOPlr2q6J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2-5pMsKcouJ"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             dtype=torch.float32)"
      ],
      "id": "j2-5pMsKcouJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s send a dummy input to our model so it can calculate the corresponding loss:"
      ],
      "metadata": {
        "id": "8tkuk9SF2tlt"
      },
      "id": "8tkuk9SF2tlt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61pQD5v8couJ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "batch = tokenizer(['This is a simple test'], return_tensors='pt')\n",
        "batch['labels'] = batch['input_ids']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch = {k: v.to(device) for k, v in batch.items()}"
      ],
      "id": "61pQD5v8couJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INur0ylwcouJ",
        "outputId": "2511c282-93db-44c5-d129-0a5831db5837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8001, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "INur0ylwcouJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVbXXhAIcouJ"
      },
      "source": [
        "#### Half-Precision Models (16-bit)"
      ],
      "id": "KVbXXhAIcouJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39itnhEGcouK",
        "outputId": "d3d7d58a-9d24-42ae-f284-2e75433a40c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "dtype16 = (torch.bfloat16 if supported else torch.float16)\n",
        "dtype16"
      ],
      "id": "39itnhEGcouK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csD9SSHjcouK",
        "outputId": "45032690-fe55-4bf6-992c-00ca837a1112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.to(dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "get_parm_dtypes(model.parameters())"
      ],
      "id": "csD9SSHjcouK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can load halfprecision\n",
        "weights directly by specifying the dtype argument when calling the from_pretrained()\n",
        "method."
      ],
      "metadata": {
        "id": "pAlgICQn37h0"
      },
      "id": "pAlgICQn37h0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzol561UcouK",
        "outputId": "e4074d24-6f10-42f4-b193-fcfd241d3e74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n",
            "[(torch.float16, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             device_map='cuda:0',\n",
        "                                             dtype=dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "Xzol561UcouK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf-Fzf-bcouK",
        "outputId": "f8936737-e8e8-45aa-d949-64ed39345d7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8012, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "Uf-Fzf-bcouK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG4z0k2acouK"
      },
      "source": [
        "### Mixed Precision"
      ],
      "id": "cG4z0k2acouK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep in mind that the goal of using mixed precision is not to reduce the model’s memory footprint but to\n",
        "speed up the forward pass."
      ],
      "metadata": {
        "id": "QemcdxodZOXN"
      },
      "id": "QemcdxodZOXN"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KkbfFYjDcouL"
      },
      "outputs": [],
      "source": [
        "class MixedModel(nn.Module):\n",
        "    def __init__(self, dtype):\n",
        "        super().__init__()\n",
        "        self.a = nn.Linear(1000, 1000, dtype=dtype)\n",
        "        self.b = nn.Linear(1000, 1000, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.b(self.a(x))"
      ],
      "id": "KkbfFYjDcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8gFPkr_1couL",
        "outputId": "5ff5f12b-650f-4abc-a413-a47f7d2dba70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "mixed32 = MixedModel(torch.float32)\n",
        "mixed32.to('cuda')"
      ],
      "id": "8gFPkr_1couL"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mVguUsezcouL",
        "outputId": "b2611434-edda-4dc1-d853-72f3ac738c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.22 ms ± 8.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "mVguUsezcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9EG2KRQbcouL",
        "outputId": "13f860c3-6742-49ef-c723-b69a2fd7c048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixedModel(\n",
              "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "mixed16 = MixedModel(torch.float16)\n",
        "mixed16.to('cuda')"
      ],
      "id": "9EG2KRQbcouL"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GTgUF0rHcouL",
        "outputId": "140577a4-fc51-4f6e-ee04-3d9f7af8c2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "213 µs ± 3.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed16(torch.randn(1000, 1000, dtype=torch.float16, device='cuda'))"
      ],
      "id": "GTgUF0rHcouL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "we’ll be using PyTorch’s\n",
        "context manager, which allows regions of\n",
        "a script to run in mixed precision with the desired data type."
      ],
      "metadata": {
        "id": "XfTt_yfCZW3w"
      },
      "id": "XfTt_yfCZW3w"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FmaQ1y4GcouM",
        "outputId": "3dbfd1d0-5189-432d-82ee-0b3e7dda79f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239 µs ± 21.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    %timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "FmaQ1y4GcouM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any output produced inside the context manager will necessarily\n",
        "have the context manager’s data type. Therefore, we’d have to cast these outputs back to FP32."
      ],
      "metadata": {
        "id": "_pNs0cWWZofs"
      },
      "id": "_pNs0cWWZofs"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jj0mqmPtcouM"
      },
      "outputs": [],
      "source": [
        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "    res16 = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "\n",
        "res32 = res16.float()"
      ],
      "id": "Jj0mqmPtcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7TdVkcD5couM"
      },
      "outputs": [],
      "source": [
        "autocast_context = torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
        "# original forward method\n",
        "model_forward_func = mixed32.forward.__func__\n",
        "# wrapping the method with the context manager\n",
        "new_forward = autocast_context(model_forward_func)\n",
        "# assigning the wrapped method back to the model\n",
        "mixed32.forward = MethodType(new_forward, mixed32)"
      ],
      "id": "7TdVkcD5couM"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fgSwTg9JcouM",
        "outputId": "b83cd5e6-9cb2-4a3c-e518-545295b6a9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "fgSwTg9JcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yRLrCoC2couM"
      },
      "outputs": [],
      "source": [
        "mixed32.forward = MethodType(convert_outputs_to_fp32(mixed32.forward.__func__), mixed32)"
      ],
      "id": "yRLrCoC2couM"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mn1tKOLUcouM",
        "outputId": "781d9912-181a-435c-87c2-a582472e91b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
        "res.dtype"
      ],
      "id": "mn1tKOLUcouM"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_jdVpWXecouM",
        "outputId": "d4ef8653-8179-4b7f-c6ea-7b3d53e5e8fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310 µs ± 2.47 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))"
      ],
      "id": "_jdVpWXecouM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxxgn5nmcouN"
      },
      "source": [
        "### BitsAndBytes\n",
        "\n",
        "[BitsAndBytes](https://huggingface.co/docs/bitsandbytes/main/en/index) is your go-to package for quantization. From its documentation:\n",
        "\n",
        "\"_bitsandbytes enables accessible large language models via k-bit quantization for PyTorch. bitsandbytes provides three main features for dramatically reducing memory consumption for inference and training:_\n",
        "\n",
        "- _8-bit optimizers uses block-wise quantization to maintain 32-bit performance at a small fraction of the memory cost._\n",
        "- _LLM.Int() or 8-bit quantization enables large language model inference with only half the required memory and without any performance degradation. This method is based on vector-wise quantization to quantize most features to 8-bits and separately treating outliers with 16-bit matrix multiplication._\n",
        "- _QLoRA or 4-bit quantization enables large language model training with several memory-saving techniques that don’t compromise performance. This method quantizes a model to 4-bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training._\""
      ],
      "id": "Dxxgn5nmcouN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "X8AM7sgecouN",
        "outputId": "412954dc-e1fa-4c7c-ef9b-af11d2f62dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BitsAndBytesConfig {\n",
              "  \"_load_in_4bit\": false,\n",
              "  \"_load_in_8bit\": false,\n",
              "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "  \"bnb_4bit_quant_type\": \"fp4\",\n",
              "  \"bnb_4bit_use_double_quant\": false,\n",
              "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "  \"llm_int8_has_fp16_weight\": false,\n",
              "  \"llm_int8_skip_modules\": null,\n",
              "  \"llm_int8_threshold\": 6.0,\n",
              "  \"load_in_4bit\": false,\n",
              "  \"load_in_8bit\": false,\n",
              "  \"quant_method\": \"bitsandbytes\"\n",
              "}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig()\n",
        "bnb_config"
      ],
      "id": "X8AM7sgecouN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udyEUr2IcouN"
      },
      "source": [
        "#### 8-Bit Quantization\n",
        "\n",
        "\"_LLM.int8() is a quantization method that doesn’t degrade performance which makes large model inference more accessible. The key is to extract the outliers from the inputs and weights and multiply them in 16-bit. All other values are multiplied in 8-bit and quantized to Int8 before being dequantized back to 16-bits. The outputs from the 16-bit and 8-bit multiplication are combined to produce the final output._\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)\n",
        "\n",
        "****\n",
        "**Summary of \"8-Bit Quantization\"**\n",
        "- load an 8-bit quantized model in a few lines of code:\n",
        "  ```python\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                                 device_map='cuda:0',\n",
        "                                                 torch_dtype=torch.float32,\n",
        "                                                 quantization_config=bnb_config)\n",
        "  ```\n",
        "  - quantization modifies the default type of non-quantized layers to `torch.float16` unless we actively provide the `torch_dtype` argument when calling the `from_pretrained()` method\n",
        "- 8-bit quantization replaces all linear layers except for:\n",
        "  - layers with tied (shared) weights\n",
        "  - the last layer in the model\n",
        "  - any layer named `lm_head`\n",
        "- if you want to skip additional modules, use the `llm_int8_skip_modules` configuration argument and make sure to manually include the layers with tied (shared) weights to avoid errors\n",
        "- computation (inside the quantized layers) happens in `torch.float16`\n",
        "****"
      ],
      "id": "udyEUr2IcouN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgNj4HDVcouN",
        "outputId": "9b1c423b-05ed-44e0-e63c-ac180b5cbe49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "359.354368\n",
            "[(torch.float16, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "bnb_config_q8 = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_q8 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8)\n",
        "print(model_q8.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8.parameters()))"
      ],
      "id": "cgNj4HDVcouN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7J4uVb_couN",
        "outputId": "e48e3cf1-8dce-487b-af9a-11d70d22785b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you may not get a NaN back, as it depends on the environment\n",
        "out = model_q8(**batch)\n",
        "out.loss"
      ],
      "id": "F7J4uVb_couN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d_kWK0UcouN",
        "outputId": "d5080d79-2042-4a42-9326-66c7edd7571e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "415.670272\n",
            "[(torch.float32, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q8_32 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8,\n",
        "                                                torch_dtype=torch.float32)\n",
        "print(model_q8_32.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8_32.parameters()))"
      ],
      "id": "0d_kWK0UcouN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp3pKOVpcouO",
        "outputId": "a518b860-0210-480b-cdfb-e56911a6da39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(3.8024, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q8_32(**batch)\n",
        "out.loss"
      ],
      "id": "Bp3pKOVpcouO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyMitVE0couO"
      },
      "source": [
        "##### Quantized Linear Layers"
      ],
      "id": "wyMitVE0couO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Plxf8KcouO",
        "outputId": "1d78ab1a-6c35-4cb4-c47d-8e2723df9ec2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q8_32.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "z_Plxf8KcouO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBlH1YMscouO",
        "outputId": "aa0dfceb-3ce9-4ee9-b341-a6e91ba48dd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear8bitLt(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_layer = dec_layer.self_attn.k_proj\n",
        "q8_layer"
      ],
      "id": "eBlH1YMscouO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za13SRWccouO",
        "outputId": "6fcb8168-2167-4acf-d0ac-a7f00a60d014"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -67, -113,  -89,  ...,   65,  -16,  -87],\n",
              "                      [  60,  120,   90,  ...,  -50,   32,   80],\n",
              "                      [  47,  127,   86,  ...,  -34,    8,   90],\n",
              "                      ...,\n",
              "                      [ -65,   65,   34,  ...,  -64,   35,   64],\n",
              "                      [  57,   67,   21,  ...,   63,  -64,  -64],\n",
              "                      [ -64,   63,  -11,  ...,  -64,   34,   63]], device='cuda:0',\n",
              "                     dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.1250, 0.1252, 0.1250,  ..., 0.1252, 0.1250, 0.1254], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_state = q8_layer.state_dict()\n",
        "q8_state"
      ],
      "id": "za13SRWccouO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCIOaNiTcouO",
        "outputId": "7e2ed656-1c8a-4525-9d7b-1494e7459139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding(50272, 512, padding_idx=1)\n",
            "Linear(in_features=512, out_features=50272, bias=False)\n"
          ]
        }
      ],
      "source": [
        "print(model.model.decoder.embed_tokens)\n",
        "print(model.lm_head)"
      ],
      "id": "yCIOaNiTcouO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdBC5TghcouQ",
        "outputId": "db480850-7edb-43e2-8728-9bf4ba427bf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(model.model.decoder.embed_tokens.weight,\n",
        "               model.lm_head.weight)"
      ],
      "id": "TdBC5TghcouQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36qswA_fcouQ",
        "outputId": "6c9f1417-af74-4c7e-d627-375c4341f710"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, [['lm_head.weight', 'model.decoder.embed_tokens.weight']])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
        "\n",
        "config.tie_word_embeddings, find_tied_parameters(model)"
      ],
      "id": "36qswA_fcouQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3NT1VkccouQ",
        "outputId": "70127df4-af9c-4abf-bf78-f497104bae2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(..., device='meta', size=(50272, 512), requires_grad=True)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with init_empty_weights(): # loads meta tensors only\n",
        "    empty_model = AutoModelForCausalLM.from_config(config)\n",
        "\n",
        "empty_model.lm_head.weight"
      ],
      "id": "w3NT1VkccouQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFC604zscouQ",
        "outputId": "cd622a28-addf-4c71-ae2d-85e1de58c2c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lm_head', 'model.decoder.embed_tokens']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skip_modules = get_keys_to_not_convert(empty_model)\n",
        "skip_modules"
      ],
      "id": "uFC604zscouQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZazkdwdcouQ",
        "outputId": "2d18027d-3c94-4b00-a8dd-1e488328ba66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lm_head: torch.float32\n",
            "model.decoder.embed_tokens: torch.float32\n"
          ]
        }
      ],
      "source": [
        "for module in skip_modules:\n",
        "    print(f'{module}: {next(model_q8_32.get_submodule(module).parameters()).dtype}')"
      ],
      "id": "TZazkdwdcouQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfzKRMGicouR"
      },
      "source": [
        "#### `llm_int8_skip_modules`\n",
        "\n",
        "If your model has tied weights, and you choose to use your own list of modules to skip, you\n",
        "must add one of the tied layers to your list. If you don’t, you may get the following\n",
        "exception:\n",
        "\n",
        "***\n",
        "`AttributeError: 'Parameter' object has no attribute 'SCB'`\n",
        "***\n",
        "\n",
        "```python\n",
        "# This configuration WILL raise an exception\n",
        "# while trying to load weights for the tied layer\n",
        "# bnb_config_skip = BitsAndBytesConfig(load_in_8bit=True,\n",
        "#                                      llm_int8_skip_modules=['o_proj'])\n",
        "\n",
        "# This configuration works fine because\n",
        "# the tied layer, lm_head, is in the list\n",
        "bnb_config_skip = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        llm_int8_skip_modules=['o_proj', 'lm_head'])\n",
        "\n",
        "model_skip = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                  device_map='cuda:0',\n",
        "                                                  torch_dtype=torch.float32,\n",
        "                                                  quantization_config=bnb_config_skip)\n",
        "```"
      ],
      "id": "UfzKRMGicouR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Xm9K9tcouR"
      },
      "source": [
        "##### 8-bit Layers\n",
        "\n",
        "\"*In order to quantize a linear layer one should first load the original fp16 / bf16 weights into the Linear8bitLt module, then call int8_module.to(\"cuda\") to quantize the fp16 weights.*\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)"
      ],
      "id": "d8Xm9K9tcouR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Egv4taFkcouR",
        "outputId": "bd8a4b7d-9578-4245-908f-a0037214e8c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.2220, -0.0085,  0.3072, -0.2097,  0.0531,  0.1224,  0.0525, -0.2350,\n",
              "                        0.0456,  0.2687],\n",
              "                      [-0.1459,  0.1786, -0.1443, -0.0233,  0.1689,  0.0015, -0.2514,  0.1644,\n",
              "                        0.1920,  0.1678],\n",
              "                      [ 0.2346,  0.1411,  0.2128,  0.0519,  0.2147, -0.2786, -0.0433, -0.0364,\n",
              "                       -0.1504,  0.0823],\n",
              "                      [ 0.2388, -0.2134, -0.1620, -0.1023,  0.2433, -0.2680,  0.3099, -0.1933,\n",
              "                       -0.0471, -0.0391],\n",
              "                      [-0.1273,  0.2197, -0.0136, -0.1938, -0.1746,  0.0404,  0.0711, -0.1730,\n",
              "                        0.0539, -0.1992],\n",
              "                      [-0.0051,  0.1373, -0.0267, -0.0907, -0.0107,  0.1108, -0.1566,  0.0172,\n",
              "                        0.2075, -0.0028],\n",
              "                      [ 0.2082, -0.2857, -0.2640, -0.1436,  0.1704,  0.1908, -0.2350,  0.1187,\n",
              "                       -0.0568,  0.0916],\n",
              "                      [ 0.2974, -0.3061,  0.0559,  0.1899,  0.0265, -0.1893, -0.0582, -0.0943,\n",
              "                        0.2451,  0.2825],\n",
              "                      [-0.1241, -0.3106, -0.1002, -0.1745,  0.2693,  0.2985,  0.1633, -0.0270,\n",
              "                       -0.3049,  0.0227],\n",
              "                      [-0.1217,  0.0035, -0.1481, -0.0330,  0.1787,  0.3123,  0.2600, -0.1720,\n",
              "                        0.2059,  0.2057]])),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854]))])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "\n",
        "torch.manual_seed(11)\n",
        "fp_layer = nn.Linear(n_in, n_out)\n",
        "\n",
        "int8_layer = Linear8bitLt(n_in, n_out, has_fp16_weights=False)\n",
        "\n",
        "int8_layer.load_state_dict(fp_layer.state_dict())\n",
        "int8_layer.state_dict()"
      ],
      "id": "Egv4taFkcouR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc8iwYmacouR",
        "outputId": "823f9a0e-525e-4f8e-fb30-e147b56effca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -92,   -4,  127,  -87,   22,   51,   22,  -97,   19,  111],\n",
              "                      [ -74,   90,  -73,  -12,   85,    1, -127,   83,   97,   85],\n",
              "                      [ 107,   64,   97,   24,   98, -127,  -20,  -17,  -69,   38],\n",
              "                      [  98,  -87,  -66,  -42,  100, -110,  127,  -79,  -19,  -16],\n",
              "                      [ -74,  127,   -8, -112, -101,   23,   41, -100,   31, -115],\n",
              "                      [  -3,   84,  -16,  -56,   -7,   68,  -96,   11,  127,   -2],\n",
              "                      [  93, -127, -117,  -64,   76,   85, -104,   53,  -25,   41],\n",
              "                      [ 123, -127,   23,   79,   11,  -79,  -24,  -39,  102,  117],\n",
              "                      [ -51, -127,  -41,  -71,  110,  122,   67,  -11, -125,    9],\n",
              "                      [ -50,    1,  -60,  -13,   73,  127,  106,  -70,   84,   84]],\n",
              "                     device='cuda:0', dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854], device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.3071, 0.2515, 0.2786, 0.3098, 0.2197, 0.2075, 0.2856, 0.3062, 0.3105,\n",
              "                      0.3123], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int8_layer = int8_layer.to(0) # Quantization happens here\n",
        "int8_state = int8_layer.state_dict()\n",
        "int8_state"
      ],
      "id": "hc8iwYmacouR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Rn3bzEcouS"
      },
      "source": [
        "#### 4-bit Quantization\n",
        "\n",
        "\"*QLoRA is a finetuning method that quantizes a model to 4-bits and adds a set of low-rank adaptation (LoRA) weights to the model and tuning them through the quantized weights. This method also introduces a new data type, 4-bit NormalFloat (LinearNF4) in addition to the standard Float4 data type (LinearFP4). LinearNF4 is a quantization data type for normally distributed data and can improve performance.*\"\n",
        "\n",
        "Source: [4-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear4bit)\n",
        "\n",
        "****\n",
        "**Summary of \"4-Bit Quantization\"**\n",
        "- squeeze the most of a 4-bit quantized model by using the normal float (NF4) type and double quantization\n",
        "  ```python\n",
        "  supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "  compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "  nf4_config = BitsAndBytesConfig(\n",
        "     load_in_4bit=True,\n",
        "     bnb_4bit_quant_type=\"nf4\",\n",
        "     bnb_4bit_use_double_quant=True,\n",
        "     bnb_4bit_compute_dtype=compute_dtype\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                               device_map='cuda:0',\n",
        "                                               torch_dtype=torch.float32,\n",
        "                                               quantization_config=nf4_config)\n",
        "  ```\n",
        "- computation happens (inside the quantized layers) in the specified type (`bnb_4bit_compute_dtype`):\n",
        "FP32 is better than BF16, which is better than FP16.\n",
        "****"
      ],
      "id": "G4Rn3bzEcouS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeL_JkppcouS"
      },
      "outputs": [],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=compute_dtype\n",
        ")"
      ],
      "id": "oeL_JkppcouS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDHXTuk8couS"
      },
      "source": [
        "**The Secret Lives of `Dtypes`**\n",
        "\n",
        "| Regular Model | Quantized Model |\n",
        "|---|---|\n",
        "| ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_regular.png?raw=True) | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_qt.png?raw=True) |\n",
        "| <center>Figure 2.6 - Data types flowing through a regular model</center> | <center>Figure 2.7 - Data types flowing through a quantized model</center> |"
      ],
      "id": "NDHXTuk8couS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDxQDfN2couS",
        "outputId": "bfbc01b4-46bb-409c-acb7-f37bb1b7be17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "264.15104\n",
            "[(torch.float32, 242), (torch.uint8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q4 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                torch_dtype=torch.float32,\n",
        "                                                quantization_config=nf4_config)\n",
        "print(model_q4.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q4.parameters()))"
      ],
      "id": "pDxQDfN2couS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHCCXE4AcouT",
        "outputId": "4e22bc0e-f1a5-4676-c3b3-46ad008549b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.7016, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q4(**batch)\n",
        "out.loss"
      ],
      "id": "kHCCXE4AcouT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUU3jtoHcouT",
        "outputId": "4cb600bf-b588-4fac-f773-9c3a4b26e7ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q4.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "CUU3jtoHcouT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg3ISjIZcouT",
        "outputId": "3e5cd1b4-e164-4049-febd-0a8dd1bc822a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear4bit(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer = dec_layer.self_attn.k_proj\n",
        "q4_layer"
      ],
      "id": "mg3ISjIZcouT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukhL6HCacouU",
        "outputId": "548dccc2-d13b-42be-8ac9-6126cba5b0ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 32],\n",
              "                      [ 29],\n",
              "                      [208],\n",
              "                      ...,\n",
              "                      [ 66],\n",
              "                      [ 34],\n",
              "                      [172]], device='cuda:0', dtype=torch.uint8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0', dtype=torch.float16)),\n",
              "             ('weight.absmax',\n",
              "              tensor([230, 230,  30,  ...,   1,  26, 191], device='cuda:0',\n",
              "                     dtype=torch.uint8)),\n",
              "             ('weight.quant_map',\n",
              "              tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "                       0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "                     device='cuda:0')),\n",
              "             ('weight.nested_absmax',\n",
              "              tensor([0.0077, 0.0142, 0.0153, 0.0138, 0.0399, 0.0409, 0.0417, 0.0426, 0.0053,\n",
              "                      0.0053, 0.0053, 0.0053, 0.0051, 0.0051, 0.0051, 0.0053, 0.0195, 0.0269,\n",
              "                      0.0223, 0.0195, 0.0053, 0.0053, 0.0054, 0.0054, 0.0317, 0.0315, 0.0306,\n",
              "                      0.0320, 0.0262, 0.0265, 0.0230, 0.0296, 0.0051, 0.0065, 0.0050, 0.0050,\n",
              "                      0.0051, 0.0053, 0.0050, 0.0051, 0.0056, 0.0056, 0.0056, 0.0056, 0.0428,\n",
              "                      0.0410, 0.0405, 0.0422, 0.0397, 0.0402, 0.0394, 0.0414, 0.0204, 0.0106,\n",
              "                      0.0140, 0.0078, 0.0406, 0.0349, 0.0359, 0.0418, 0.0503, 0.0499, 0.0470,\n",
              "                      0.0458], device='cuda:0')),\n",
              "             ('weight.nested_quant_map',\n",
              "              tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
              "                      -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
              "                      -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
              "                      -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
              "                      -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
              "                      -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
              "                      -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
              "                      -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
              "                      -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
              "                      -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
              "                      -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
              "                      -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
              "                      -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
              "                      -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
              "                      -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
              "                      -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
              "                      -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
              "                      -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
              "                      -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
              "                      -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
              "                      -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
              "                      -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
              "                      -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
              "                      -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
              "                      -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
              "                      -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
              "                       7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
              "                       1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
              "                       7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
              "                       2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
              "                       5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
              "                       8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
              "                       1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
              "                       2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
              "                       4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
              "                       5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
              "                       7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
              "                       8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
              "                       9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
              "                       1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
              "                       2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
              "                       3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
              "                       3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
              "                       4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
              "                       5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
              "                       5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
              "                       6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
              "                       7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
              "                       7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
              "                       8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
              "                       9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
              "                       1.0000e+00], device='cuda:0')),\n",
              "             ('weight.quant_state.bitsandbytes__nf4',\n",
              "              tensor([123,  34, 113, 117,  97, 110, 116,  95, 116, 121, 112, 101,  34,  58,\n",
              "                       32,  34, 110, 102,  52,  34,  44,  32,  34,  98, 108, 111,  99, 107,\n",
              "                      115, 105, 122, 101,  34,  58,  32,  54,  52,  44,  32,  34, 100, 116,\n",
              "                      121, 112, 101,  34,  58,  32,  34, 102, 108, 111,  97, 116,  49,  54,\n",
              "                       34,  44,  32,  34, 115, 104,  97, 112, 101,  34,  58,  32,  91,  49,\n",
              "                       48,  50,  52,  44,  32,  49,  48,  50,  52,  93,  44,  32,  34, 110,\n",
              "                      101, 115, 116, 101, 100,  95,  98, 108, 111,  99, 107, 115, 105, 122,\n",
              "                      101,  34,  58,  32,  50,  53,  54,  44,  32,  34, 110, 101, 115, 116,\n",
              "                      101, 100,  95, 100, 116, 121, 112, 101,  34,  58,  32,  34, 102, 108,\n",
              "                      111,  97, 116,  51,  50,  34,  44,  32,  34, 110, 101, 115, 116, 101,\n",
              "                      100,  95, 111, 102, 102, 115, 101, 116,  34,  58,  32,  48,  46,  49,\n",
              "                       49,  57,  57,  56,  49,  55,  50,  49,  48,  52,  51,  53,  56,  54,\n",
              "                       55,  51, 125], dtype=torch.uint8))])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer.state_dict()"
      ],
      "id": "ukhL6HCacouU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14FQv-kcouU"
      },
      "source": [
        "##### FP4 vs NF4 Layers"
      ],
      "id": "l14FQv-kcouU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhnFSUHLcouU",
        "outputId": "56d6d084-c9e1-4237-f046-294e86fa7164"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "torch.manual_seed(11)\n",
        "fp16_layer = nn.Linear(n_in, n_out)\n",
        "fp16_layer"
      ],
      "id": "YhnFSUHLcouU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhFRo-XNcouU",
        "outputId": "5f43fd25-1a4f-460d-c1da-96c207eda2b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = LinearFP4(n_in, n_out)\n",
        "fp4_layer.load_state_dict(fp16_layer.state_dict())\n",
        "\n",
        "nf4_model = LinearNF4(n_in, n_out)\n",
        "nf4_model.load_state_dict(fp16_layer.state_dict())"
      ],
      "id": "WhFRo-XNcouU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiiUHsSNcouU",
        "outputId": "764cbd45-77d8-4435-ee26-5d10f1ff42b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
              "          0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = fp4_layer.to(0) # Quantization happens here\n",
        "fp4_state = fp4_layer.state_dict()\n",
        "\n",
        "fp4_state['weight.quant_map'], fp4_state['weight'].shape"
      ],
      "id": "QiiUHsSNcouU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7g3b9ShcouU",
        "outputId": "d02f90e1-6797-42ca-88b3-8d8f7d5bb57a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'FP4 quantization')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(fp4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('FP4 quantization')"
      ],
      "id": "-7g3b9ShcouU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP0avxs6couU",
        "outputId": "f5a3b7c3-df22-4ed6-886d-ba5fcf855012"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nf4_model = nf4_model.to(0) # Quantization happens here\n",
        "nf4_state = nf4_model.state_dict()\n",
        "\n",
        "nf4_state['weight.quant_map'], nf4_state['weight'].shape"
      ],
      "id": "JP0avxs6couU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqVn1Or4couU",
        "outputId": "fb23d727-6ae5-4d78-911b-5889062ddc09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'NF4 quantization')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(nf4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('NF4 quantization')"
      ],
      "id": "fqVn1Or4couU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPK-WKvMcouV"
      },
      "source": [
        "### Coming Up in \"Fine-Tuning LLMs\"\n",
        "\n",
        "As huge linear layers are being replaced by their quantized versions to reduce the model’s memory footprint, a\n",
        "new issue arises. These quantized layers cannot be easily updated, thus rendering fine-tuning next to\n",
        "impossible. Could a new kind of layer be the solution to this conundrum? Find out in the next thrilling chapter\n",
        "of \"Fine-Tuning LLMs.\""
      ],
      "id": "tPK-WKvMcouV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}